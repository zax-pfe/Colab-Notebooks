{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"00_Générer_un_Texte_avec_RNNs.ipynb","provenance":[{"file_id":"18PXAarXiDDeOK6ASISFeNVCHtzMEHiHC","timestamp":1602689613777}],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.5"}},"cells":[{"cell_type":"markdown","metadata":{"id":"ovpZyIhNIgoq"},"source":["# Génération de texte avec les réseaux de neurones\n","\n","Dans ce notebook, nous allons créer un réseau qui peut générer du texte, ici nous montrons que cela se fait caractère par caractère. Super post à lire ici : http://karpathy.github.io/2015/05/21/rnn-effectiveness/\n","\n","Nous avons organisé le processus en \"étapes\" afin que vous puissiez suivre facilement avec vos propres ensembles de données."]},{"cell_type":"code","metadata":{"id":"WBd69MDEm4rF"},"source":["import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import tensorflow as tf"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"apj1Chkdm4rS"},"source":["## Étape 1 : Les Données\n","\n","Vous pouvez récupérer n'importe quel texte gratuit ici : https://www.gutenberg.org/\n","\n","Nous allons choisir toutes les œuvres de Shakespeare (que nous avons déjà téléchargées pour vous), principalement pour deux raisons :\n","\n","1. C'est un grand corpus de textes, il est généralement recommandé d'avoir au moins une source d'un million de caractères au total pour obtenir une génération de texte réaliste.\n","\n","2. Il a un style très particulier. Comme les données textuelles utilisent un anglais ancien et sont formatées dans le style d'une pièce de théâtre, il nous apparaîtra très clairement si le modèle est capable de reproduire des résultats similaires."]},{"cell_type":"code","metadata":{"id":"pD_55cOxLkAb"},"source":["path_to_file = 'shakespeare.txt'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"aavnuByVymwK"},"source":["text = open(path_to_file, 'r').read()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Duhg9NrUymwO","colab":{"base_uri":"https://localhost:8080/","height":238},"executionInfo":{"status":"ok","timestamp":1602930741748,"user_tz":-120,"elapsed":1874,"user":{"displayName":"Rod Paris","photoUrl":"","userId":"10535238717210992784"}},"outputId":"2584308b-dd14-4c61-ca97-1aa17da70881"},"source":["print(text[:500])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\n","                     1\n","  From fairest creatures we desire increase,\n","  That thereby beauty's rose might never die,\n","  But as the riper should by time decease,\n","  His tender heir might bear his memory:\n","  But thou contracted to thine own bright eyes,\n","  Feed'st thy light's flame with self-substantial fuel,\n","  Making a famine where abundance lies,\n","  Thy self thy foe, to thy sweet self too cruel:\n","  Thou that art now the world's fresh ornament,\n","  And only herald to the gaudy spring,\n","  Within thine own bu\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"XXUmR627m4rd"},"source":["### Comprendre les caractères uniques"]},{"cell_type":"code","metadata":{"id":"IlCgQBRVymwR","colab":{"base_uri":"https://localhost:8080/","height":71},"executionInfo":{"status":"ok","timestamp":1602930741749,"user_tz":-120,"elapsed":1865,"user":{"displayName":"Rod Paris","photoUrl":"","userId":"10535238717210992784"}},"outputId":"8879523a-8460-444a-f81f-b10410a41698"},"source":["# Les caractères uniques dans le fichier\n","vocab = sorted(set(text))\n","print(vocab)\n","len(vocab)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["['\\n', ' ', '!', '\"', '&', \"'\", '(', ')', ',', '-', '.', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '<', '>', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', '[', ']', '_', '`', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '|', '}']\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["84"]},"metadata":{"tags":[]},"execution_count":5}]},{"cell_type":"markdown","metadata":{"id":"rNnrKn_lL-IJ"},"source":["## Étape 2 : Traitement du texte"]},{"cell_type":"markdown","metadata":{"id":"LFjSVAlWzf-N"},"source":["### Vectorisation du texte\n","\n","Nous savons qu'un réseau de neurones ne peut pas prendre en charge les données brutes des chaînes de caractères, nous devons attribuer des numéros à chaque caractère. Créons deux dictionnaires qui peuvent passer d'un index numérique à un caractère et d'un caractère à un index numérique."]},{"cell_type":"code","metadata":{"id":"IalZLbvOzf-F"},"source":["char_to_ind = {u:i for i, u in enumerate(vocab)}"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fmmP5iCwm4rp","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1602930741750,"user_tz":-120,"elapsed":1848,"user":{"displayName":"Rod Paris","photoUrl":"","userId":"10535238717210992784"}},"outputId":"0faf8b7f-afb2-45f4-f2ac-5f585762d763"},"source":["char_to_ind"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'\\n': 0,\n"," ' ': 1,\n"," '!': 2,\n"," '\"': 3,\n"," '&': 4,\n"," \"'\": 5,\n"," '(': 6,\n"," ')': 7,\n"," ',': 8,\n"," '-': 9,\n"," '.': 10,\n"," '0': 11,\n"," '1': 12,\n"," '2': 13,\n"," '3': 14,\n"," '4': 15,\n"," '5': 16,\n"," '6': 17,\n"," '7': 18,\n"," '8': 19,\n"," '9': 20,\n"," ':': 21,\n"," ';': 22,\n"," '<': 23,\n"," '>': 24,\n"," '?': 25,\n"," 'A': 26,\n"," 'B': 27,\n"," 'C': 28,\n"," 'D': 29,\n"," 'E': 30,\n"," 'F': 31,\n"," 'G': 32,\n"," 'H': 33,\n"," 'I': 34,\n"," 'J': 35,\n"," 'K': 36,\n"," 'L': 37,\n"," 'M': 38,\n"," 'N': 39,\n"," 'O': 40,\n"," 'P': 41,\n"," 'Q': 42,\n"," 'R': 43,\n"," 'S': 44,\n"," 'T': 45,\n"," 'U': 46,\n"," 'V': 47,\n"," 'W': 48,\n"," 'X': 49,\n"," 'Y': 50,\n"," 'Z': 51,\n"," '[': 52,\n"," ']': 53,\n"," '_': 54,\n"," '`': 55,\n"," 'a': 56,\n"," 'b': 57,\n"," 'c': 58,\n"," 'd': 59,\n"," 'e': 60,\n"," 'f': 61,\n"," 'g': 62,\n"," 'h': 63,\n"," 'i': 64,\n"," 'j': 65,\n"," 'k': 66,\n"," 'l': 67,\n"," 'm': 68,\n"," 'n': 69,\n"," 'o': 70,\n"," 'p': 71,\n"," 'q': 72,\n"," 'r': 73,\n"," 's': 74,\n"," 't': 75,\n"," 'u': 76,\n"," 'v': 77,\n"," 'w': 78,\n"," 'x': 79,\n"," 'y': 80,\n"," 'z': 81,\n"," '|': 82,\n"," '}': 83}"]},"metadata":{"tags":[]},"execution_count":7}]},{"cell_type":"code","metadata":{"id":"30ZYaWAOm4rt"},"source":["ind_to_char = np.array(vocab)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_6JPOWwJm4rz","colab":{"base_uri":"https://localhost:8080/","height":136},"executionInfo":{"status":"ok","timestamp":1602930741751,"user_tz":-120,"elapsed":1827,"user":{"displayName":"Rod Paris","photoUrl":"","userId":"10535238717210992784"}},"outputId":"5a5438b9-fed8-4428-e4c0-52bf8d5e9248"},"source":["ind_to_char"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array(['\\n', ' ', '!', '\"', '&', \"'\", '(', ')', ',', '-', '.', '0', '1',\n","       '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '<', '>', '?',\n","       'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M',\n","       'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z',\n","       '[', ']', '_', '`', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i',\n","       'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v',\n","       'w', 'x', 'y', 'z', '|', '}'], dtype='<U1')"]},"metadata":{"tags":[]},"execution_count":9}]},{"cell_type":"code","metadata":{"id":"3fhOqV0lm4r2"},"source":["encoded_text = np.array([char_to_ind[c] for c in text])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"axOX7rFom4r5","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1602930742901,"user_tz":-120,"elapsed":2926,"user":{"displayName":"Rod Paris","photoUrl":"","userId":"10535238717210992784"}},"outputId":"963165a3-4479-4747-b185-10da30a2795d"},"source":["encoded_text"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([ 0,  1,  1, ..., 30, 39, 29])"]},"metadata":{"tags":[]},"execution_count":11}]},{"cell_type":"markdown","metadata":{"id":"tZfqhkYCymwX"},"source":["Nous disposons maintenant d'un mapping que nous pouvons utiliser pour passer des caractères aux chiffres."]},{"cell_type":"code","metadata":{"id":"tFs1Uza-m4r9","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1602930742902,"user_tz":-120,"elapsed":2909,"user":{"displayName":"Rod Paris","photoUrl":"","userId":"10535238717210992784"}},"outputId":"5dcbbf22-e8fa-4c99-fc59-abb44d177b9a"},"source":["sample = text[:20]\n","sample"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'\\n                   '"]},"metadata":{"tags":[]},"execution_count":12}]},{"cell_type":"code","metadata":{"id":"gIqUCK5Am4sB","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1602930742903,"user_tz":-120,"elapsed":2901,"user":{"displayName":"Rod Paris","photoUrl":"","userId":"10535238717210992784"}},"outputId":"5a736bed-3cd1-4435-9860-bbd37f41e092"},"source":["encoded_text[:20]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])"]},"metadata":{"tags":[]},"execution_count":13}]},{"cell_type":"markdown","metadata":{"id":"bbmsf23Bymwe"},"source":["## Étape 3 : Création de batches\n","\n","Globalement, ce que nous essayons de faire, c'est de faire en sorte que le modèle prévoie le caractère suivant le plus probable, compte tenu d'une séquence historique de caractères. C'est à nous (l'utilisateur) de choisir la longueur de cette séquence historique. Une séquence trop courte et nous n'aurons pas assez d'informations (par exemple, étant donné la lettre \"a\", quel est le prochain caractère), une séquence trop longue et l'entraînement prendra trop de temps et risque de sur-entraîner (au risque d'obtenir une séquence de caractères qui ne sont pas pertinents pour des caractères plus éloignés). Bien qu'il n'y ait pas de choix correct de longueur de séquence, vous devez considérer le texte lui-même, la longueur des phrases normales qu'il contient et avoir une idée raisonnable des caractères/mots qui sont pertinents les uns pour les autres."]},{"cell_type":"code","metadata":{"id":"pAvUYFk7m4sF","colab":{"base_uri":"https://localhost:8080/","height":238},"executionInfo":{"status":"ok","timestamp":1602930742903,"user_tz":-120,"elapsed":2890,"user":{"displayName":"Rod Paris","photoUrl":"","userId":"10535238717210992784"}},"outputId":"31f37b30-08fb-4686-ebd7-32abc963b4f6"},"source":["print(text[:500])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\n","                     1\n","  From fairest creatures we desire increase,\n","  That thereby beauty's rose might never die,\n","  But as the riper should by time decease,\n","  His tender heir might bear his memory:\n","  But thou contracted to thine own bright eyes,\n","  Feed'st thy light's flame with self-substantial fuel,\n","  Making a famine where abundance lies,\n","  Thy self thy foe, to thy sweet self too cruel:\n","  Thou that art now the world's fresh ornament,\n","  And only herald to the gaudy spring,\n","  Within thine own bu\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"D45OYgOfm4sJ"},"source":["line = \"From fairest creatures we desire increase\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7dKiEVN8m4sL","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1602930742907,"user_tz":-120,"elapsed":2876,"user":{"displayName":"Rod Paris","photoUrl":"","userId":"10535238717210992784"}},"outputId":"5056d152-409c-4fe9-f473-88e234b66251"},"source":["len(line)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["41"]},"metadata":{"tags":[]},"execution_count":16}]},{"cell_type":"code","metadata":{"id":"olX67f6-m4sP"},"source":["part_stanza = \"\"\"From fairest creatures we desire increase,\n","  That thereby beauty's rose might never die,\n","  But as the riper should by time decease,\"\"\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qal7MQnqm4sQ","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1602930742910,"user_tz":-120,"elapsed":2859,"user":{"displayName":"Rod Paris","photoUrl":"","userId":"10535238717210992784"}},"outputId":"3238469c-9269-45ed-e5ba-722c07c2bbc4"},"source":["len(part_stanza)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["131"]},"metadata":{"tags":[]},"execution_count":18}]},{"cell_type":"markdown","metadata":{"id":"hgsVvVxnymwf"},"source":["### Séquences d'Entraînement\n","\n","Les données textuelles réelles seront la séquence de texte décalée d'un caractère vers l'avant. \n","\n","Par exemple :\n","\n","*   Sequence In: \"Hello my nam\"\n","*   Sequence Out: \"ello my name\"\n","\n","Nous pouvons utiliser la fonction `tf.data.Dataset.from_tensor_slices` pour convertir un vecteur de texte en un flux d'indices de caractères."]},{"cell_type":"code","metadata":{"id":"0UHJDA39zf-O"},"source":["seq_len = 120"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7VRSK4cOm4sZ"},"source":["total_num_seq = len(text)//(seq_len+1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xtW0jbbvm4sc","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1602930742911,"user_tz":-120,"elapsed":2833,"user":{"displayName":"Rod Paris","photoUrl":"","userId":"10535238717210992784"}},"outputId":"26617712-ad32-4d4d-d6e2-56057d3449e4"},"source":["total_num_seq"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["45005"]},"metadata":{"tags":[]},"execution_count":21}]},{"cell_type":"code","metadata":{"id":"ciatnowvm4se","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1602930748538,"user_tz":-120,"elapsed":8451,"user":{"displayName":"Rod Paris","photoUrl":"","userId":"10535238717210992784"}},"outputId":"367d416d-6d03-4e21-b7a0-385c9d2f9242"},"source":["# Création des séquences d'entraînement\n","char_dataset = tf.data.Dataset.from_tensor_slices(encoded_text)\n","\n","for i in char_dataset.take(500):\n","     print(ind_to_char[i.numpy()])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\n","\n"," \n"," \n"," \n"," \n"," \n"," \n"," \n"," \n"," \n"," \n"," \n"," \n"," \n"," \n"," \n"," \n"," \n"," \n"," \n"," \n"," \n","1\n","\n","\n"," \n"," \n","F\n","r\n","o\n","m\n"," \n","f\n","a\n","i\n","r\n","e\n","s\n","t\n"," \n","c\n","r\n","e\n","a\n","t\n","u\n","r\n","e\n","s\n"," \n","w\n","e\n"," \n","d\n","e\n","s\n","i\n","r\n","e\n"," \n","i\n","n\n","c\n","r\n","e\n","a\n","s\n","e\n",",\n","\n","\n"," \n"," \n","T\n","h\n","a\n","t\n"," \n","t\n","h\n","e\n","r\n","e\n","b\n","y\n"," \n","b\n","e\n","a\n","u\n","t\n","y\n","'\n","s\n"," \n","r\n","o\n","s\n","e\n"," \n","m\n","i\n","g\n","h\n","t\n"," \n","n\n","e\n","v\n","e\n","r\n"," \n","d\n","i\n","e\n",",\n","\n","\n"," \n"," \n","B\n","u\n","t\n"," \n","a\n","s\n"," \n","t\n","h\n","e\n"," \n","r\n","i\n","p\n","e\n","r\n"," \n","s\n","h\n","o\n","u\n","l\n","d\n"," \n","b\n","y\n"," \n","t\n","i\n","m\n","e\n"," \n","d\n","e\n","c\n","e\n","a\n","s\n","e\n",",\n","\n","\n"," \n"," \n","H\n","i\n","s\n"," \n","t\n","e\n","n\n","d\n","e\n","r\n"," \n","h\n","e\n","i\n","r\n"," \n","m\n","i\n","g\n","h\n","t\n"," \n","b\n","e\n","a\n","r\n"," \n","h\n","i\n","s\n"," \n","m\n","e\n","m\n","o\n","r\n","y\n",":\n","\n","\n"," \n"," \n","B\n","u\n","t\n"," \n","t\n","h\n","o\n","u\n"," \n","c\n","o\n","n\n","t\n","r\n","a\n","c\n","t\n","e\n","d\n"," \n","t\n","o\n"," \n","t\n","h\n","i\n","n\n","e\n"," \n","o\n","w\n","n\n"," \n","b\n","r\n","i\n","g\n","h\n","t\n"," \n","e\n","y\n","e\n","s\n",",\n","\n","\n"," \n"," \n","F\n","e\n","e\n","d\n","'\n","s\n","t\n"," \n","t\n","h\n","y\n"," \n","l\n","i\n","g\n","h\n","t\n","'\n","s\n"," \n","f\n","l\n","a\n","m\n","e\n"," \n","w\n","i\n","t\n","h\n"," \n","s\n","e\n","l\n","f\n","-\n","s\n","u\n","b\n","s\n","t\n","a\n","n\n","t\n","i\n","a\n","l\n"," \n","f\n","u\n","e\n","l\n",",\n","\n","\n"," \n"," \n","M\n","a\n","k\n","i\n","n\n","g\n"," \n","a\n"," \n","f\n","a\n","m\n","i\n","n\n","e\n"," \n","w\n","h\n","e\n","r\n","e\n"," \n","a\n","b\n","u\n","n\n","d\n","a\n","n\n","c\n","e\n"," \n","l\n","i\n","e\n","s\n",",\n","\n","\n"," \n"," \n","T\n","h\n","y\n"," \n","s\n","e\n","l\n","f\n"," \n","t\n","h\n","y\n"," \n","f\n","o\n","e\n",",\n"," \n","t\n","o\n"," \n","t\n","h\n","y\n"," \n","s\n","w\n","e\n","e\n","t\n"," \n","s\n","e\n","l\n","f\n"," \n","t\n","o\n","o\n"," \n","c\n","r\n","u\n","e\n","l\n",":\n","\n","\n"," \n"," \n","T\n","h\n","o\n","u\n"," \n","t\n","h\n","a\n","t\n"," \n","a\n","r\n","t\n"," \n","n\n","o\n","w\n"," \n","t\n","h\n","e\n"," \n","w\n","o\n","r\n","l\n","d\n","'\n","s\n"," \n","f\n","r\n","e\n","s\n","h\n"," \n","o\n","r\n","n\n","a\n","m\n","e\n","n\n","t\n",",\n","\n","\n"," \n"," \n","A\n","n\n","d\n"," \n","o\n","n\n","l\n","y\n"," \n","h\n","e\n","r\n","a\n","l\n","d\n"," \n","t\n","o\n"," \n","t\n","h\n","e\n"," \n","g\n","a\n","u\n","d\n","y\n"," \n","s\n","p\n","r\n","i\n","n\n","g\n",",\n","\n","\n"," \n"," \n","W\n","i\n","t\n","h\n","i\n","n\n"," \n","t\n","h\n","i\n","n\n","e\n"," \n","o\n","w\n","n\n"," \n","b\n","u\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"-ZSYAcQV8OGP"},"source":["La méthode du **batch** convertit ces appels de caractères individuels en séquences que nous pouvons alimenter en lot. Nous utilisons seq_len+1 en raison de l'indexation zéro. \n","\n","Voici ce que signifie drop_remainder :\n","\n","drop_remainder: (Optional.) A `tf.bool` scalar `tf.Tensor`, representing\n","    whether the last batch should be dropped in the case it has fewer than\n","    `batch_size` elements; the default behavior is not to drop the smaller\n","    batch.\n"]},{"cell_type":"code","metadata":{"id":"l4hkDU3i7ozi"},"source":["sequences = char_dataset.batch(seq_len+1, drop_remainder=True)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UbLcIPBj_mWZ"},"source":["Maintenant que nous avons nos séquences, nous allons effectuer les étapes suivantes pour chacune d'entre elles afin de créer nos séquences de texte cible :\n","\n","1. Saisir la séquence de texte d'entrée\n","2. Assigner la séquence de texte cible comme séquence de texte d'entrée décalée d'un pas en avant\n","3. Regroupez-les en un tuple"]},{"cell_type":"code","metadata":{"id":"9NGu-FkO_kYU"},"source":["def create_seq_targets(seq):\n","    input_txt = seq[:-1]\n","    target_txt = seq[1:]\n","    return input_txt, target_txt"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"HszljTg8m4so"},"source":["dataset = sequences.map(create_seq_targets)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"JkPa7AMrm4sq","colab":{"base_uri":"https://localhost:8080/","height":374},"executionInfo":{"status":"ok","timestamp":1602930748541,"user_tz":-120,"elapsed":8420,"user":{"displayName":"Rod Paris","photoUrl":"","userId":"10535238717210992784"}},"outputId":"d9978d0e-7d7a-4224-f68b-4176031cc321"},"source":["for input_txt, target_txt in  dataset.take(1):\n","    print(input_txt.numpy())\n","    print(''.join(ind_to_char[input_txt.numpy()]))\n","    print('\\n')\n","    print(target_txt.numpy())\n","    # Il y a un espace supplémentaire !\n","    print(''.join(ind_to_char[target_txt.numpy()]))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[ 0  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 12  0\n","  1  1 31 73 70 68  1 61 56 64 73 60 74 75  1 58 73 60 56 75 76 73 60 74\n","  1 78 60  1 59 60 74 64 73 60  1 64 69 58 73 60 56 74 60  8  0  1  1 45\n"," 63 56 75  1 75 63 60 73 60 57 80  1 57 60 56 76 75 80  5 74  1 73 70 74\n"," 60  1 68 64 62 63 75  1 69 60 77 60 73  1 59 64 60  8  0  1  1 27 76 75]\n","\n","                     1\n","  From fairest creatures we desire increase,\n","  That thereby beauty's rose might never die,\n","  But\n","\n","\n","[ 1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 12  0  1\n","  1 31 73 70 68  1 61 56 64 73 60 74 75  1 58 73 60 56 75 76 73 60 74  1\n"," 78 60  1 59 60 74 64 73 60  1 64 69 58 73 60 56 74 60  8  0  1  1 45 63\n"," 56 75  1 75 63 60 73 60 57 80  1 57 60 56 76 75 80  5 74  1 73 70 74 60\n","  1 68 64 62 63 75  1 69 60 77 60 73  1 59 64 60  8  0  1  1 27 76 75  1]\n","                     1\n","  From fairest creatures we desire increase,\n","  That thereby beauty's rose might never die,\n","  But \n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"MJdfPmdqzf-R"},"source":["### Générer des batches d'entraînement\n","\n","Maintenant que nous avons les séquences réelles, nous allons créer les lots, nous voulons mélanger ces séquences dans un ordre aléatoire, de sorte que le modèle ne s'adapte à aucune section du texte, mais puisse au contraire générer des caractères à partir de n'importe quel texte de départ."]},{"cell_type":"code","metadata":{"id":"p2pGotuNzf-S"},"source":["# Taille de batch\n","batch_size = 128\n","\n","# Taille de la mémoire tampon pour mélanger l'ensemble des données \n","# afin de ne pas tenter de mélanger toute la séquence en mémoire. \n","# Au lieu de cela, il maintient une mémoire tampon dans laquelle \n","# il mélange les éléments\n","buffer_size = 10000\n","\n","dataset = dataset.shuffle(buffer_size).batch(batch_size, drop_remainder=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gmcCALymm4su","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1602930748542,"user_tz":-120,"elapsed":8406,"user":{"displayName":"Rod Paris","photoUrl":"","userId":"10535238717210992784"}},"outputId":"2863b0b1-719d-46bd-ae3b-71c634b2c22a"},"source":["dataset"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<BatchDataset shapes: ((128, 120), (128, 120)), types: (tf.int64, tf.int64)>"]},"metadata":{"tags":[]},"execution_count":28}]},{"cell_type":"markdown","metadata":{"id":"r6oUuElIMgVx"},"source":["## Étape 4 : Création du modèle"]},{"cell_type":"markdown","metadata":{"id":"m8gPwEjRzf-Z"},"source":["Nous utiliserons un modèle basé sur le LSTM avec quelques caractéristiques supplémentaires, notamment une couche embedding pour commencer et **deux** couches LSTM. Nous avons basé cette architecture de modèle sur le [DeepMoji](https://deepmoji.mit.edu/) et le code source original peut être trouvé [ici](https://github.com/bfelbo/DeepMoji).\n","\n","La couche embedding servira de couche d'entrée, qui crée essentiellement une table de consultation qui fait correspondre les indices numériques de chaque caractère à un vecteur avec un nombre de dimensions \"embedding dim\". Comme vous pouvez l'imaginer, plus cette taille d'embedding est grande, plus l'entraînement est complexe. C'est similaire à l'idée derrière word2vec, où les mots sont mis en correspondance avec un espace à n dimensions. L'embedding avant le feeding directe dans le LSTM conduit généralement à des résultats plus réalistes."]},{"cell_type":"code","metadata":{"id":"zHT8cLh7EAsg"},"source":["# Longueur du vocabulaire en caractères\n","vocab_size = len(vocab)\n","\n","# La dimension embedding\n","embed_dim = 64\n","\n","# Nombre d'unitées RNN\n","rnn_neurons = 1026"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Atb060h5m4s0"},"source":["Créons maintenant une fonction qui s'adapte facilement aux différentes variables comme indiqué ci-dessus."]},{"cell_type":"code","metadata":{"id":"YeRlEXgym4s1"},"source":["from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import LSTM,Dense,Embedding,Dropout,GRU"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"FcMbIy-xj-w-"},"source":["### Mise en place de la fonction de perte\n","\n","Pour notre perte, nous utiliserons une crossentropie catégorique peu dense (sparse_categorical_crossentropy), que nous pouvons importer de Keras. Nous définirons également ce paramètre logits=True"]},{"cell_type":"code","metadata":{"id":"VoFVGKlNkJfW"},"source":["from tensorflow.keras.losses import sparse_categorical_crossentropy"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"sblCzZoslZKH","colab":{"base_uri":"https://localhost:8080/","height":442},"executionInfo":{"status":"ok","timestamp":1602930748544,"user_tz":-120,"elapsed":8376,"user":{"displayName":"Rod Paris","photoUrl":"","userId":"10535238717210992784"}},"outputId":"4fcb556e-dee5-47c9-f9af-10aa3468897f"},"source":["help(sparse_categorical_crossentropy)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Help on function sparse_categorical_crossentropy in module tensorflow.python.keras.losses:\n","\n","sparse_categorical_crossentropy(y_true, y_pred, from_logits=False, axis=-1)\n","    Computes the sparse categorical crossentropy loss.\n","    \n","    Standalone usage:\n","    \n","    >>> y_true = [1, 2]\n","    >>> y_pred = [[0.05, 0.95, 0], [0.1, 0.8, 0.1]]\n","    >>> loss = tf.keras.losses.sparse_categorical_crossentropy(y_true, y_pred)\n","    >>> assert loss.shape == (2,)\n","    >>> loss.numpy()\n","    array([0.0513, 2.303], dtype=float32)\n","    \n","    Args:\n","      y_true: Ground truth values.\n","      y_pred: The predicted values.\n","      from_logits: Whether `y_pred` is expected to be a logits tensor. By default,\n","        we assume that `y_pred` encodes a probability distribution.\n","      axis: (Optional) Defaults to -1. The dimension along which the entropy is\n","        computed.\n","    \n","    Returns:\n","      Sparse categorical crossentropy loss value.\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"y5N4Qxbij5gY"},"source":["https://datascience.stackexchange.com/questions/41921/sparse-categorical-crossentropy-vs-categorical-crossentropy-keras-accuracy"]},{"cell_type":"code","metadata":{"id":"FrOOK61Olm1C"},"source":["def sparse_cat_loss(y_true,y_pred):\n","  return sparse_categorical_crossentropy(y_true, y_pred, from_logits=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MtCrdfzEI2N0"},"source":["def create_model(vocab_size, embed_dim, rnn_neurons, batch_size):\n","    model = Sequential()\n","    model.add(Embedding(vocab_size, embed_dim,batch_input_shape=[batch_size, None]))\n","    model.add(GRU(rnn_neurons,return_sequences=True,stateful=True,recurrent_initializer='glorot_uniform'))\n","    # Couche Finale Dense de Prédiction\n","    model.add(Dense(vocab_size))\n","    model.compile(optimizer='adam', loss=sparse_cat_loss) \n","    return model"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wwsrpOik5zhv"},"source":["model = create_model(\n","  vocab_size = vocab_size,\n","  embed_dim=embed_dim,\n","  rnn_neurons=rnn_neurons,\n","  batch_size=batch_size)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"liXuTFYMm4s6","colab":{"base_uri":"https://localhost:8080/","height":255},"executionInfo":{"status":"ok","timestamp":1602930748862,"user_tz":-120,"elapsed":8665,"user":{"displayName":"Rod Paris","photoUrl":"","userId":"10535238717210992784"}},"outputId":"b0c20ce3-ec18-4dd2-966a-5e194dee397b"},"source":["model.summary()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model: \"sequential\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","embedding (Embedding)        (128, None, 64)           5376      \n","_________________________________________________________________\n","gru (GRU)                    (128, None, 1026)         3361176   \n","_________________________________________________________________\n","dense (Dense)                (128, None, 84)           86268     \n","=================================================================\n","Total params: 3,452,820\n","Trainable params: 3,452,820\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"LJL0Q0YPY6Ee"},"source":["## Étape 5 : Entraînement du modèle\n","\n","Assurons-nous que tout va bien avec notre modèle avant de passer trop de temps sur l'entraînement ! Passons en lot pour confirmer que le modèle prédit actuellement des caractères aléatoires sans aucun entraînement.\n","\n"]},{"cell_type":"code","metadata":{"id":"A4ygvfHn-wan","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1602930756360,"user_tz":-120,"elapsed":16156,"user":{"displayName":"Rod Paris","photoUrl":"","userId":"10535238717210992784"}},"outputId":"97168251-32ee-47ef-809e-7a49816de877"},"source":["for input_example_batch, target_example_batch in dataset.take(1):\n","\n","  # Prédire sur un lot aléatoire\n","  example_batch_predictions = model(input_example_batch)\n","\n","  # Afficher les dimensions des prédictions\n","  print(example_batch_predictions.shape, \" <=== (batch_size, sequence_length, vocab_size)\")\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["(128, 120, 84)  <=== (batch_size, sequence_length, vocab_size)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"5ld8z3LPBAuv","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1602930756361,"user_tz":-120,"elapsed":16149,"user":{"displayName":"Rod Paris","photoUrl":"","userId":"10535238717210992784"}},"outputId":"bd986329-b59f-466e-ae60-42cd7948cc97"},"source":["example_batch_predictions"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tf.Tensor: shape=(128, 120, 84), dtype=float32, numpy=\n","array([[[-3.80827906e-03,  8.72645702e-04,  5.13616716e-03, ...,\n","          1.54101034e-03, -1.83233968e-03, -7.58333644e-03],\n","        [-5.28332032e-03,  1.08895488e-02,  6.62506279e-03, ...,\n","         -2.90334481e-03,  1.66666694e-03, -3.19830561e-03],\n","        [-3.33068054e-03,  2.28975131e-03,  4.56009805e-03, ...,\n","         -2.70648696e-03,  1.43409753e-03,  3.01969890e-03],\n","        ...,\n","        [ 3.87038430e-03,  2.44528218e-03,  2.37170211e-03, ...,\n","         -2.98482249e-03, -4.78985300e-03, -4.76485444e-03],\n","        [ 3.92475352e-03, -4.05428093e-03, -6.58480451e-04, ...,\n","         -2.79931747e-03, -1.76895363e-03,  1.84032950e-03],\n","        [-1.80049869e-03, -2.31877924e-03,  3.09810229e-03, ...,\n","         -8.51220742e-04,  3.15416208e-03,  6.80467067e-03]],\n","\n","       [[-4.40484553e-04, -3.22631653e-03,  1.98761001e-03, ...,\n","         -5.31909754e-04, -1.20747136e-04,  3.51941399e-03],\n","        [-1.65335264e-03, -9.29711154e-04,  2.48836051e-03, ...,\n","         -1.68925489e-03, -3.55764758e-04,  1.08807522e-03],\n","        [-1.03956438e-03, -2.09370919e-04,  1.51857361e-03, ...,\n","         -2.57703150e-03, -6.01545256e-03, -2.07741791e-03],\n","        ...,\n","        [ 1.92750967e-03,  4.39107092e-03,  1.42996886e-03, ...,\n","         -5.86223882e-03,  3.74617847e-03,  2.83503067e-03],\n","        [ 2.31942115e-03, -2.04295781e-03,  2.75872322e-03, ...,\n","         -3.75586748e-03,  1.73319550e-03,  6.53570145e-03],\n","        [-1.98772992e-04,  6.26800815e-04, -1.44239597e-03, ...,\n","         -3.80309974e-03,  2.54137814e-03,  6.67181145e-03]],\n","\n","       [[-1.16374646e-03, -4.21079545e-04,  1.09057385e-03, ...,\n","         -3.88832879e-04,  2.54326267e-04, -1.98999560e-03],\n","        [ 1.04668457e-03, -8.25753342e-03,  9.52664763e-04, ...,\n","          9.60329664e-04,  2.56150262e-04, -1.57228438e-03],\n","        [ 1.61870406e-03, -1.15339682e-02,  8.68992414e-04, ...,\n","          2.28819641e-04,  1.46841560e-03,  1.24224753e-04],\n","        ...,\n","        [-7.99277332e-05, -1.31317310e-03,  4.70355898e-03, ...,\n","         -4.14772512e-04, -9.33251111e-04, -2.65102973e-03],\n","        [-6.82093436e-04,  3.05610069e-04,  3.06936214e-03, ...,\n","         -9.28464637e-04, -5.12574916e-04, -2.54607573e-03],\n","        [ 6.42526988e-03,  6.73171715e-04,  2.81741680e-03, ...,\n","         -1.82101317e-03,  1.52974704e-03,  2.76302453e-05]],\n","\n","       ...,\n","\n","       [[ 5.74837439e-04, -7.70454993e-04,  2.96298671e-03, ...,\n","          1.40200183e-03,  5.28338412e-03, -6.31096074e-03],\n","        [ 1.25685846e-03, -1.22022047e-03,  5.79510443e-03, ...,\n","          3.34774540e-03,  8.89375247e-03, -1.04658417e-02],\n","        [ 1.85106252e-03, -1.43417297e-03,  7.87523203e-03, ...,\n","          5.00120549e-03,  1.12641454e-02, -1.30956192e-02],\n","        ...,\n","        [ 2.90202443e-03, -1.58082345e-04,  3.48250079e-03, ...,\n","          5.23118675e-03,  4.95328754e-03,  4.55707312e-04],\n","        [-6.07100083e-04, -1.62207172e-03, -1.05032860e-03, ...,\n","         -2.51638191e-03,  3.18997516e-03,  9.03649139e-04],\n","        [-2.49157514e-04, -9.15811979e-04,  9.05274763e-04, ...,\n","         -1.54083222e-03,  3.64473136e-03, -1.75957126e-03]],\n","\n","       [[ 5.74837439e-04, -7.70454993e-04,  2.96298671e-03, ...,\n","          1.40200183e-03,  5.28338412e-03, -6.31096074e-03],\n","        [ 3.01481807e-03,  2.32237298e-03,  2.85954541e-03, ...,\n","          3.19819269e-03,  2.53252918e-04, -5.32732066e-03],\n","        [-1.71385100e-03,  1.52449135e-03,  6.79880986e-03, ...,\n","          4.01211344e-03, -1.53795886e-03, -1.11194663e-02],\n","        ...,\n","        [-8.85200687e-04, -4.79998020e-03, -2.60841823e-03, ...,\n","         -2.02846737e-03,  4.88890451e-04,  3.45666846e-03],\n","        [-1.14119239e-03, -1.34709887e-02, -2.63999752e-03, ...,\n","          4.94313892e-03,  1.06715709e-02,  1.45177415e-04],\n","        [-9.12301010e-04, -6.97040698e-03,  1.23580126e-03, ...,\n","          2.98037310e-03,  9.68982279e-03, -6.10943697e-03]],\n","\n","       [[ 5.74837439e-04, -7.70454993e-04,  2.96298671e-03, ...,\n","          1.40200183e-03,  5.28338412e-03, -6.31096074e-03],\n","        [-4.77442518e-04, -8.80009553e-04,  3.91143980e-03, ...,\n","          1.55375991e-03,  3.86933424e-03, -6.14164816e-03],\n","        [-3.25034419e-03,  4.96679102e-04,  7.19825458e-03, ...,\n","          4.17799968e-03,  5.64085552e-04, -1.10896537e-02],\n","        ...,\n","        [ 1.50797237e-03, -4.81476076e-03,  4.77699004e-03, ...,\n","         -1.36604044e-03, -9.79026547e-04,  4.76087257e-03],\n","        [-2.65053031e-03, -1.13475882e-03,  5.38182212e-03, ...,\n","         -9.81793739e-04,  2.60788016e-03,  8.51263478e-03],\n","        [-1.71533902e-04,  4.68671089e-03,  6.43840246e-03, ...,\n","         -2.14569038e-03,  3.05033266e-03,  4.41940548e-03]]],\n","      dtype=float32)>"]},"metadata":{"tags":[]},"execution_count":38}]},{"cell_type":"code","metadata":{"id":"_achqjT-BGyY"},"source":["sampled_indices = tf.random.categorical(example_batch_predictions[0], num_samples=1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xWrPFk2nBJX4","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1602930756362,"user_tz":-120,"elapsed":16131,"user":{"displayName":"Rod Paris","photoUrl":"","userId":"10535238717210992784"}},"outputId":"bc7c4a2d-2de5-4940-cdd9-db8ad23f43d1"},"source":["sampled_indices"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tf.Tensor: shape=(120, 1), dtype=int64, numpy=\n","array([[53],\n","       [44],\n","       [46],\n","       [11],\n","       [14],\n","       [18],\n","       [50],\n","       [23],\n","       [57],\n","       [30],\n","       [35],\n","       [48],\n","       [22],\n","       [68],\n","       [16],\n","       [27],\n","       [32],\n","       [ 9],\n","       [ 5],\n","       [44],\n","       [ 4],\n","       [40],\n","       [25],\n","       [42],\n","       [ 6],\n","       [72],\n","       [48],\n","       [32],\n","       [69],\n","       [67],\n","       [ 7],\n","       [27],\n","       [10],\n","       [45],\n","       [ 7],\n","       [23],\n","       [82],\n","       [ 4],\n","       [74],\n","       [33],\n","       [58],\n","       [74],\n","       [73],\n","       [38],\n","       [60],\n","       [45],\n","       [27],\n","       [23],\n","       [11],\n","       [61],\n","       [27],\n","       [ 6],\n","       [23],\n","       [44],\n","       [27],\n","       [24],\n","       [ 2],\n","       [65],\n","       [34],\n","       [70],\n","       [38],\n","       [36],\n","       [78],\n","       [75],\n","       [ 0],\n","       [ 2],\n","       [75],\n","       [23],\n","       [10],\n","       [34],\n","       [52],\n","       [38],\n","       [64],\n","       [40],\n","       [ 6],\n","       [51],\n","       [34],\n","       [ 9],\n","       [70],\n","       [22],\n","       [25],\n","       [45],\n","       [47],\n","       [53],\n","       [61],\n","       [ 2],\n","       [26],\n","       [17],\n","       [83],\n","       [36],\n","       [81],\n","       [ 1],\n","       [73],\n","       [63],\n","       [39],\n","       [58],\n","       [44],\n","       [14],\n","       [16],\n","       [34],\n","       [39],\n","       [47],\n","       [31],\n","       [48],\n","       [41],\n","       [ 6],\n","       [48],\n","       [33],\n","       [61],\n","       [29],\n","       [11],\n","       [60],\n","       [18],\n","       [63],\n","       [50],\n","       [60],\n","       [46],\n","       [28],\n","       [35],\n","       [47]])>"]},"metadata":{"tags":[]},"execution_count":40}]},{"cell_type":"code","metadata":{"id":"Wi80PQVtBLqj"},"source":["# Reformater pour ne pas être une liste de listes\n","sampled_indices = tf.squeeze(sampled_indices,axis=-1).numpy()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4qYkIg00-wjq","colab":{"base_uri":"https://localhost:8080/","height":153},"executionInfo":{"status":"ok","timestamp":1602930756363,"user_tz":-120,"elapsed":16117,"user":{"displayName":"Rod Paris","photoUrl":"","userId":"10535238717210992784"}},"outputId":"e0620402-ca7b-4abc-d276-27028a9c3c76"},"source":["sampled_indices"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([53, 44, 46, 11, 14, 18, 50, 23, 57, 30, 35, 48, 22, 68, 16, 27, 32,\n","        9,  5, 44,  4, 40, 25, 42,  6, 72, 48, 32, 69, 67,  7, 27, 10, 45,\n","        7, 23, 82,  4, 74, 33, 58, 74, 73, 38, 60, 45, 27, 23, 11, 61, 27,\n","        6, 23, 44, 27, 24,  2, 65, 34, 70, 38, 36, 78, 75,  0,  2, 75, 23,\n","       10, 34, 52, 38, 64, 40,  6, 51, 34,  9, 70, 22, 25, 45, 47, 53, 61,\n","        2, 26, 17, 83, 36, 81,  1, 73, 63, 39, 58, 44, 14, 16, 34, 39, 47,\n","       31, 48, 41,  6, 48, 33, 61, 29, 11, 60, 18, 63, 50, 60, 46, 28, 35,\n","       47])"]},"metadata":{"tags":[]},"execution_count":42}]},{"cell_type":"code","metadata":{"id":"H9-P_XqQ_7wY","colab":{"base_uri":"https://localhost:8080/","height":204},"executionInfo":{"status":"ok","timestamp":1602930756364,"user_tz":-120,"elapsed":16109,"user":{"displayName":"Rod Paris","photoUrl":"","userId":"10535238717210992784"}},"outputId":"8bb0385e-ce6b-4656-e738-5cc73ecc04f6"},"source":["print(\"Compte tenu de la séquence d'entrée : \\n\")\n","print(\"\".join(ind_to_char[input_example_batch[0]]))\n","print('\\n')\n","print(\"Prochain caractère prédit : \\n\")\n","print(\"\".join(ind_to_char[sampled_indices ]))\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Compte tenu de la séquence d'entrée : \n","\n","ngthened though more weak in seeming,\n","  I love not less, though less the show appear,\n","  That love is merchandized, whose\n","\n","\n","Prochain caractère prédit : \n","\n","]SU037Y<bEJW;m5BG-'S&O?Q(qWGnl)B.T)<|&sHcsrMeTB<0fB(<SB>!jIoMKwt\n","!t<.I[MiO(ZI-o;?TV]f!A6}Kz rhNcS35INVFWP(WHfD0e7hYeUCJV\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"DAOE4rzuBh7f"},"source":["Après avoir confirmé que les dimensions fonctionnent, entraînons notre réseau !"]},{"cell_type":"code","metadata":{"id":"ZYDQjKTlm4s8"},"source":["epochs = 30"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_PJ4OVdBm4s8","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1602932122076,"user_tz":-120,"elapsed":1196,"user":{"displayName":"Rod Paris","photoUrl":"","userId":"10535238717210992784"}},"outputId":"91c0791c-3278-41d9-ee85-cc128043a398"},"source":["model.fit(dataset,epochs=epochs)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/30\n","351/351 [==============================] - 41s 117ms/step - loss: 2.5422\n","Epoch 2/30\n","351/351 [==============================] - 43s 124ms/step - loss: 1.7559\n","Epoch 3/30\n","351/351 [==============================] - 45s 129ms/step - loss: 1.4800\n","Epoch 4/30\n","351/351 [==============================] - 45s 127ms/step - loss: 1.3541\n","Epoch 5/30\n","351/351 [==============================] - 44s 127ms/step - loss: 1.2888\n","Epoch 6/30\n","351/351 [==============================] - 46s 130ms/step - loss: 1.2460\n","Epoch 7/30\n","351/351 [==============================] - 44s 125ms/step - loss: 1.2152\n","Epoch 8/30\n","351/351 [==============================] - 44s 125ms/step - loss: 1.1911\n","Epoch 9/30\n","351/351 [==============================] - 44s 127ms/step - loss: 1.1707\n","Epoch 10/30\n","351/351 [==============================] - 45s 129ms/step - loss: 1.1529\n","Epoch 11/30\n","351/351 [==============================] - 45s 127ms/step - loss: 1.1368\n","Epoch 12/30\n","351/351 [==============================] - 44s 127ms/step - loss: 1.1229\n","Epoch 13/30\n","351/351 [==============================] - 45s 129ms/step - loss: 1.1094\n","Epoch 14/30\n","351/351 [==============================] - 44s 125ms/step - loss: 1.0966\n","Epoch 15/30\n","351/351 [==============================] - 44s 125ms/step - loss: 1.0847\n","Epoch 16/30\n","351/351 [==============================] - 44s 126ms/step - loss: 1.0731\n","Epoch 17/30\n","351/351 [==============================] - 45s 129ms/step - loss: 1.0622\n","Epoch 18/30\n","351/351 [==============================] - 45s 127ms/step - loss: 1.0516\n","Epoch 19/30\n","351/351 [==============================] - 45s 127ms/step - loss: 1.0422\n","Epoch 20/30\n","351/351 [==============================] - 45s 130ms/step - loss: 1.0324\n","Epoch 21/30\n","351/351 [==============================] - 44s 125ms/step - loss: 1.0243\n","Epoch 22/30\n","351/351 [==============================] - 44s 126ms/step - loss: 1.0178\n","Epoch 23/30\n","351/351 [==============================] - 44s 126ms/step - loss: 1.0093\n","Epoch 24/30\n","351/351 [==============================] - 45s 128ms/step - loss: 1.0019\n","Epoch 25/30\n","351/351 [==============================] - 45s 127ms/step - loss: 0.9963\n","Epoch 26/30\n","351/351 [==============================] - 44s 126ms/step - loss: 0.9909\n","Epoch 27/30\n","351/351 [==============================] - 45s 129ms/step - loss: 0.9856\n","Epoch 28/30\n","351/351 [==============================] - 44s 125ms/step - loss: 0.9822\n","Epoch 29/30\n","351/351 [==============================] - 44s 125ms/step - loss: 0.9775\n","Epoch 30/30\n","351/351 [==============================] - 44s 126ms/step - loss: 0.9742\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x7fdd6446dda0>"]},"metadata":{"tags":[]},"execution_count":45}]},{"cell_type":"markdown","metadata":{"id":"kKkD5M6eoSiN"},"source":["## Étape 6 : Génération du texte\n","\n","Actuellement, notre modèle ne prévoit que 128 séquences à la fois. Nous pouvons créer un nouveau modèle qui n'attend qu'un batch_size=1. Nous pouvons créer un nouveau modèle avec cette taille de batch, puis charger les poids de nos modèles sauvegardés. Ensuite, appelez .build() sur le modèle :"]},{"cell_type":"code","metadata":{"id":"eYRNG57Govdc"},"source":["model.save('shakespeare_gen.h5')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"GCoJayFS8H4d"},"source":["from tensorflow.keras.models import load_model"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_iXG3VJvEXWM"},"source":["model = create_model(vocab_size, embed_dim, rnn_neurons, batch_size=1)\n","\n","model.load_weights('shakespeare_gen.h5')\n","\n","model.build(tf.TensorShape([1, None]))\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LAX3p7_YEilU","colab":{"base_uri":"https://localhost:8080/","height":255},"executionInfo":{"status":"ok","timestamp":1602932122080,"user_tz":-120,"elapsed":26,"user":{"displayName":"Rod Paris","photoUrl":"","userId":"10535238717210992784"}},"outputId":"9fe3c8b9-c25a-4fcf-9ab1-7c8ab9c4a61b"},"source":["model.summary()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model: \"sequential_1\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","embedding_1 (Embedding)      (1, None, 64)             5376      \n","_________________________________________________________________\n","gru_1 (GRU)                  (1, None, 1026)           3361176   \n","_________________________________________________________________\n","dense_1 (Dense)              (1, None, 84)             86268     \n","=================================================================\n","Total params: 3,452,820\n","Trainable params: 3,452,820\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"WvuwZBX5Ogfd"},"source":["def generate_text(model, start_seed,gen_size=100,temp=1.0):\n","  '''\n","  model: Modèle Entraîné pour générer du texte\n","  start_seed: Seed initial du texte sous forme de chaîne de caractères\n","  gen_size: Nombre de caractères à générer\n","\n","  L'idée de base de cette fonction est de prendre un texte de départ, de le formater de manière à\n","  qu'il soit dans le bon format pour notre réseau, puis bouclez la séquence à mesure que\n","  nous continuons d'ajouter nos propres caractères prédits. Similaire à notre notre travail au sein \n","  des problèmes de séries temporelles avec le RNN.\n","  '''\n","\n","  # Nombre de caractères à générer\n","  num_generate = gen_size\n","\n","  # Vectorisation du texte du seed de départ\n","  input_eval = [char_to_ind[s] for s in start_seed]\n","\n","  # Étendre les dimensions pour correspondre à la forme du format de batch\n","  input_eval = tf.expand_dims(input_eval, 0)\n","\n","  # Liste vide pour contenir le texte généré\n","  text_generated = []\n","\n","  # La température a un effet aléatoire sur le texte qui en résulte\n","  # Le terme est dérivé de l'entropie/thermodynamique.\n","  # La température est utilisée pour affecter la probabilité des caractères suivants.\n","  # Probabilité plus élevée == moins surprenante/ plus attendue\n","  # Une température plus basse == plus surprenante / moins attendue\n"," \n","  temperature = temp\n","\n","  # Ici batch size == 1\n","  model.reset_states()\n","\n","  for i in range(num_generate):\n","\n","      # Générer des prédictions\n","      predictions = model(input_eval)\n","\n","      # Supprimer la dimension de la forme du batch\n","      predictions = tf.squeeze(predictions, 0)\n","\n","      # Utilisez une distribution catégorielle pour sélectionner le caractère suivant\n","      predictions = predictions / temperature\n","      predicted_id = tf.random.categorical(predictions, num_samples=1)[-1,0].numpy()\n","\n","      # Passez le caractère prédit pour la prochaine entrée\n","      input_eval = tf.expand_dims([predicted_id], 0)\n","\n","      # Transformer à nouveau en lettre de caractère\n","      text_generated.append(ind_to_char[predicted_id])\n","\n","  return (start_seed + ''.join(text_generated))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bS69SG5D5lwd","colab":{"base_uri":"https://localhost:8080/","height":493},"executionInfo":{"status":"ok","timestamp":1602932125094,"user_tz":-120,"elapsed":3025,"user":{"displayName":"Rod Paris","photoUrl":"","userId":"10535238717210992784"}},"outputId":"b8f747d2-c8bf-44f7-b7d4-d61049088911"},"source":["print(generate_text(model,\"flower\",gen_size=1000))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["flower,\n","    In thy one from my sorrows, bid finds of these d Knock,\n","    Ready signior.\n","\n","                TROILUS and MAYORNO find\n","\n","  PETRUCHIO. Thus shall your life is on a poor thing sweet love.  \n","  CAMILLO. Pyille and his brow; which we may parted\n","    over manner.\n","  SERVANT. Ay, mine women.                           Exeunt\n","\n","\n","\n","\n","SCENE IV.\n","Boh. Come, Sir Thurio, fame; and that's coming forth. Pray, cherish,\n","    one speak for, besides to be to yakn; all sorts I see is Ca'ta throath.\n","  GREMIO. A wedded indume care done to Mercury,\n","    From whom he brought us with your royal person\n","    And wound thee of!  \n","  QUEEN ELIZABETH. Cry to your hand, 'So in himself!\n","  SPEED. Not a resolv'd love, sure; if you lie one of them.\n","    Make practise all the world more necessary.\n","    But hear her, let my life have life to you alone.\n","  PETRUCHIO. Here is a nunsion.\n","  SILVIA. Are you in,\n","    I curse the better now that titles or no; nay, witch deep precious queen.\n","    This sort for these unspeal, fair warrant whee\n"],"name":"stdout"}]}]}