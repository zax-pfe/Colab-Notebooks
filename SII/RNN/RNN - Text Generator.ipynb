{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.7"},"colab":{"name":"RNN - Text Generator.ipynb","provenance":[]}},"cells":[{"cell_type":"markdown","metadata":{"id":"Mt68soynTDek"},"source":["# RNN with tensorflow2.0"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cP1Tv0vqTDen","executionInfo":{"status":"ok","timestamp":1615382523668,"user_tz":-60,"elapsed":665,"user":{"displayName":"Axel Puech","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjBYZ2jCEfVY61tMOjfGATwIpwvX368uNMu2bf4Xg=s64","userId":"01637125792908796850"}},"outputId":"67d97b2c-0678-4d3c-e307-7a26cef6e6e6"},"source":["import tensorflow as tf\n","import numpy as np\n","from google.colab import drive\n","drive.mount('/content/drive/')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"U8XGCI53TDen"},"source":["## Be sure to used Tensorflow 2.0"]},{"cell_type":"code","metadata":{"id":"vXHafF_aTDeo"},"source":["assert hasattr(tf, \"function\") # Be sure to use tensorflow 2.0"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"B7Hj5fYTTDeo"},"source":["## Open and process dataset"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hbtTCvbYTDep","executionInfo":{"status":"ok","timestamp":1615382524225,"user_tz":-60,"elapsed":1215,"user":{"displayName":"Axel Puech","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjBYZ2jCEfVY61tMOjfGATwIpwvX368uNMu2bf4Xg=s64","userId":"01637125792908796850"}},"outputId":"cb571092-34f2-41e0-8751-aff010cb7e54"},"source":["# You can used your own dataset with english text\n","\n","with open(\"drive/MyDrive/rnn_dataset/victorhugo.txt\", \"r\") as f:\n","    text = f.read()\n","\n","print(len(text))\n","\n","print(text[:1000])\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["127286\n","Parce que, jargonnant vêpres, jeûne et vigile,\n","Exploitant Dieu qui rêve au fond du firmament,\n","Vous avez, au milieu du divin évangile,\n","Ouvert boutique effrontément ;\n","\n","Parce que vous feriez prendre à Jésus la verge,\n","Cyniques brocanteurs sortis on ne sait d'où ;\n","Parce que vous allez vendant la sainte vierge\n","Dix sous avec miracle, et sans miracle un sou ;\n","\n","Parce que vous contez d'effroyables sornettes\n","Qui font des temples saints trembler les vieux piliers ;\n","Parce que votre style éblouit les lunettes\n","Des duègnes et des marguilliers ;\n","\n","Parce que la soutane est sous vos redingotes,\n","Parce que vous sentez la crasse et non l'œillet,\n","Parce que vous bâclez un journal de bigotes\n","Pensé par Escobar, écrit par Patouillet ;\n","\n","Parce qu'en balayant leurs portes, les concierges\n","Poussent dans le ruisseau ce pamphlet méprisé ;\n","Parce que vous mêlez à la cire des cierges\n","Votre affreux suif vert-de-grisé ;\n","\n","Parce qu'à vous tout seuls vous faites une espèce\n","Parce qu'enfin, blanchis dehors et noirs dedans,\n","Criant\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"VaHBPrMuTDep"},"source":["## Remove character and create vocab\n","![](./images/rnn_vocab.png)"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ydkzt_-RTDeq","executionInfo":{"status":"ok","timestamp":1615382540008,"user_tz":-60,"elapsed":5013,"user":{"displayName":"Axel Puech","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjBYZ2jCEfVY61tMOjfGATwIpwvX368uNMu2bf4Xg=s64","userId":"01637125792908796850"}},"outputId":"22a85623-3fc6-4196-edac-d3a639d127de"},"source":["!pip install unidecode\n","import unidecode\n","\n","text = unidecode.unidecode(text)\n","text = text.lower()\n","\n","text = text.replace(\"2\", \"\")\n","text = text.replace(\"1\", \"\")\n","text = text.replace(\"8\", \"\")\n","text = text.replace(\"5\", \"\")\n","text = text.replace(\">\", \"\")\n","text = text.replace(\"<\", \"\")\n","text = text.replace(\"!\", \"\")\n","text = text.replace(\"?\", \"\")\n","text = text.replace(\"-\", \"\")\n","text = text.replace(\"$\", \"\")\n","\n","text = text.strip()\n","\n","vocab = set(text)\n","print(len(vocab), vocab)\n","\n","print(text[:1000])\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting unidecode\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9e/25/723487ca2a52ebcee88a34d7d1f5a4b80b793f179ee0f62d5371938dfa01/Unidecode-1.2.0-py2.py3-none-any.whl (241kB)\n","\r\u001b[K     |█▍                              | 10kB 14.8MB/s eta 0:00:01\r\u001b[K     |██▊                             | 20kB 11.4MB/s eta 0:00:01\r\u001b[K     |████                            | 30kB 7.7MB/s eta 0:00:01\r\u001b[K     |█████▍                          | 40kB 7.3MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 51kB 3.9MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 61kB 4.4MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 71kB 4.6MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 81kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 92kB 5.2MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 102kB 4.2MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 112kB 4.2MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 122kB 4.2MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 133kB 4.2MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 143kB 4.2MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 153kB 4.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 163kB 4.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 174kB 4.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 184kB 4.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 194kB 4.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 204kB 4.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 215kB 4.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 225kB 4.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 235kB 4.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 245kB 4.2MB/s \n","\u001b[?25hInstalling collected packages: unidecode\n","Successfully installed unidecode-1.2.0\n","34 {'e', 'x', ',', 's', 'w', 'i', 'l', 'k', 'a', 'v', 'q', '.', 'g', 'c', 'r', 'h', 'y', 'j', 'd', 'u', 'p', ':', ' ', 'o', 'z', 'f', 'b', '\\n', ';', \"'\", 'n', 'm', '\"', 't'}\n","parce que, jargonnant vepres, jeune et vigile,\n","exploitant dieu qui reve au fond du firmament,\n","vous avez, au milieu du divin evangile,\n","ouvert boutique effrontement ;\n","\n","parce que vous feriez prendre a jesus la verge,\n","cyniques brocanteurs sortis on ne sait d'ou ;\n","parce que vous allez vendant la sainte vierge\n","dix sous avec miracle, et sans miracle un sou ;\n","\n","parce que vous contez d'effroyables sornettes\n","qui font des temples saints trembler les vieux piliers ;\n","parce que votre style eblouit les lunettes\n","des duegnes et des marguilliers ;\n","\n","parce que la soutane est sous vos redingotes,\n","parce que vous sentez la crasse et non l'oeillet,\n","parce que vous baclez un journal de bigotes\n","pense par escobar, ecrit par patouillet ;\n","\n","parce qu'en balayant leurs portes, les concierges\n","poussent dans le ruisseau ce pamphlet meprise ;\n","parce que vous melez a la cire des cierges\n","votre affreux suif vertdegrise ;\n","\n","parce qu'a vous tout seuls vous faites une espece\n","parce qu'enfin, blanchis dehors et noirs dedans,\n","criant \n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"_TpiWFtdTDeq"},"source":["## Map each letter to int"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CkaTtm2OTDer","executionInfo":{"status":"ok","timestamp":1615382551557,"user_tz":-60,"elapsed":651,"user":{"displayName":"Axel Puech","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjBYZ2jCEfVY61tMOjfGATwIpwvX368uNMu2bf4Xg=s64","userId":"01637125792908796850"}},"outputId":"81fcb44e-193d-4194-8c80-85cbd896c22c"},"source":["vocab_size = len(vocab)\n","\n","vocab_to_int = {l:i for i,l in enumerate(vocab)}\n","int_to_vocab = {i:l for i,l in enumerate(vocab)}\n","\n","print(\"vocab_to_int\", vocab_to_int)\n","print()\n","print(\"int_to_vocab\", int_to_vocab)\n","\n","print(\"\\nint for e:\", vocab_to_int[\"e\"])\n","int_for_e = vocab_to_int[\"e\"]\n","print(\"letter for %s: %s\" % (vocab_to_int[\"e\"], int_to_vocab[int_for_e]))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["vocab_to_int {'e': 0, 'x': 1, ',': 2, 's': 3, 'w': 4, 'i': 5, 'l': 6, 'k': 7, 'a': 8, 'v': 9, 'q': 10, '.': 11, 'g': 12, 'c': 13, 'r': 14, 'h': 15, 'y': 16, 'j': 17, 'd': 18, 'u': 19, 'p': 20, ':': 21, ' ': 22, 'o': 23, 'z': 24, 'f': 25, 'b': 26, '\\n': 27, ';': 28, \"'\": 29, 'n': 30, 'm': 31, '\"': 32, 't': 33}\n","\n","int_to_vocab {0: 'e', 1: 'x', 2: ',', 3: 's', 4: 'w', 5: 'i', 6: 'l', 7: 'k', 8: 'a', 9: 'v', 10: 'q', 11: '.', 12: 'g', 13: 'c', 14: 'r', 15: 'h', 16: 'y', 17: 'j', 18: 'd', 19: 'u', 20: 'p', 21: ':', 22: ' ', 23: 'o', 24: 'z', 25: 'f', 26: 'b', 27: '\\n', 28: ';', 29: \"'\", 30: 'n', 31: 'm', 32: '\"', 33: 't'}\n","\n","int for e: 0\n","letter for 0: e\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0LhDpIUJTDer","executionInfo":{"status":"ok","timestamp":1615382552087,"user_tz":-60,"elapsed":1176,"user":{"displayName":"Axel Puech","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjBYZ2jCEfVY61tMOjfGATwIpwvX368uNMu2bf4Xg=s64","userId":"01637125792908796850"}},"outputId":"2e6e2e0c-5537-4e0e-a712-d426f2361a43"},"source":["encoded = [vocab_to_int[l] for l in text]\n","encoded_sentence = encoded[:100]\n","\n","print(encoded_sentence)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[20, 8, 14, 13, 0, 22, 10, 19, 0, 2, 22, 17, 8, 14, 12, 23, 30, 30, 8, 30, 33, 22, 9, 0, 20, 14, 0, 3, 2, 22, 17, 0, 19, 30, 0, 22, 0, 33, 22, 9, 5, 12, 5, 6, 0, 2, 27, 0, 1, 20, 6, 23, 5, 33, 8, 30, 33, 22, 18, 5, 0, 19, 22, 10, 19, 5, 22, 14, 0, 9, 0, 22, 8, 19, 22, 25, 23, 30, 18, 22, 18, 19, 22, 25, 5, 14, 31, 8, 31, 0, 30, 33, 2, 27, 9, 23, 19, 3, 22, 8]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ab7OzEqWTDer","executionInfo":{"status":"ok","timestamp":1615382552088,"user_tz":-60,"elapsed":1173,"user":{"displayName":"Axel Puech","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjBYZ2jCEfVY61tMOjfGATwIpwvX368uNMu2bf4Xg=s64","userId":"01637125792908796850"}},"outputId":"b5f574fc-3e6e-4173-c1dc-408140449a17"},"source":["decoded_sentence = [int_to_vocab[i] for i in encoded_sentence]\n","print(decoded_sentence)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["['p', 'a', 'r', 'c', 'e', ' ', 'q', 'u', 'e', ',', ' ', 'j', 'a', 'r', 'g', 'o', 'n', 'n', 'a', 'n', 't', ' ', 'v', 'e', 'p', 'r', 'e', 's', ',', ' ', 'j', 'e', 'u', 'n', 'e', ' ', 'e', 't', ' ', 'v', 'i', 'g', 'i', 'l', 'e', ',', '\\n', 'e', 'x', 'p', 'l', 'o', 'i', 't', 'a', 'n', 't', ' ', 'd', 'i', 'e', 'u', ' ', 'q', 'u', 'i', ' ', 'r', 'e', 'v', 'e', ' ', 'a', 'u', ' ', 'f', 'o', 'n', 'd', ' ', 'd', 'u', ' ', 'f', 'i', 'r', 'm', 'a', 'm', 'e', 'n', 't', ',', '\\n', 'v', 'o', 'u', 's', ' ', 'a']\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZhQa21YYTDes","executionInfo":{"status":"ok","timestamp":1615382552088,"user_tz":-60,"elapsed":1170,"user":{"displayName":"Axel Puech","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjBYZ2jCEfVY61tMOjfGATwIpwvX368uNMu2bf4Xg=s64","userId":"01637125792908796850"}},"outputId":"f91b846f-5174-4e12-d6f7-cdece861e25d"},"source":["decoded_sentence = \"\".join(decoded_sentence)\n","print(decoded_sentence)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["parce que, jargonnant vepres, jeune et vigile,\n","exploitant dieu qui reve au fond du firmament,\n","vous a\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"g1t0coEITDes"},"source":["## Sample of one batch\n","<img src=\"./images/rnn_letter.png\" width=\"400px\" ></img>"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-hg0R_6KTDes","executionInfo":{"status":"ok","timestamp":1615382552089,"user_tz":-60,"elapsed":1166,"user":{"displayName":"Axel Puech","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjBYZ2jCEfVY61tMOjfGATwIpwvX368uNMu2bf4Xg=s64","userId":"01637125792908796850"}},"outputId":"1d74fd37-8b92-4c36-d4ed-368a5eb95a37"},"source":["inputs, targets = encoded, encoded[1:]\n","\n","print(\"Inputs\", inputs[:10])\n","print(\"Targets\", targets[:10])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Inputs [20, 8, 14, 13, 0, 22, 10, 19, 0, 2]\n","Targets [8, 14, 13, 0, 22, 10, 19, 0, 2, 22]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"V_CkO-wkTDes"},"source":["## Method used to generate batch in sequence order"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gmkN2E1ITDet","executionInfo":{"status":"ok","timestamp":1615382552089,"user_tz":-60,"elapsed":1162,"user":{"displayName":"Axel Puech","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjBYZ2jCEfVY61tMOjfGATwIpwvX368uNMu2bf4Xg=s64","userId":"01637125792908796850"}},"outputId":"8a43270c-532f-4029-d5c4-c9581edd5756"},"source":["def gen_batch(inputs, targets, seq_len, batch_size, noise=0):\n","    # Size of each chunk\n","    chuck_size = (len(inputs) -1)  // batch_size\n","    # Numbef of sequence per chunk\n","    sequences_per_chunk = chuck_size // seq_len\n","\n","    for s in range(0, sequences_per_chunk):\n","        batch_inputs = np.zeros((batch_size, seq_len))\n","        batch_targets = np.zeros((batch_size, seq_len))\n","        for b in range(0, batch_size):\n","            fr = (b*chuck_size)+(s*seq_len)\n","            to = fr+seq_len\n","            batch_inputs[b] = inputs[fr:to]\n","            batch_targets[b] = inputs[fr+1:to+1]\n","            \n","            if noise > 0:\n","                noise_indices = np.random.choice(seq_len, noise)\n","                batch_inputs[b][noise_indices] = np.random.randint(0, vocab_size)\n","            \n","        yield batch_inputs, batch_targets\n","\n","for batch_inputs, batch_targets in gen_batch(inputs, targets, 5, 32, noise=0):\n","    print(batch_inputs[0], batch_targets[0])\n","    break\n","\n","for batch_inputs, batch_targets in gen_batch(inputs, targets, 5, 32, noise=3):\n","    print(batch_inputs[0], batch_targets[0])\n","    break"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[20.  8. 14. 13.  0.] [ 8. 14. 13.  0. 22.]\n","[ 3.  8. 14.  3.  0.] [ 8. 14. 13.  0. 22.]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"SDcYp9WCTDet"},"source":["## Create your own layer"]},{"cell_type":"code","metadata":{"id":"wT3Wz2MCTDet"},"source":["class OneHot(tf.keras.layers.Layer):\n","    def __init__(self, depth, **kwargs):\n","        super(OneHot, self).__init__(**kwargs)\n","        self.depth = depth\n","\n","    def call(self, x, mask=None):\n","        return tf.one_hot(tf.cast(x, tf.int32), self.depth)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"q3EXbrW6TDeu"},"source":["Test if the layer works well"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AL-FdeHpTDeu","executionInfo":{"status":"ok","timestamp":1615382553035,"user_tz":-60,"elapsed":2102,"user":{"displayName":"Axel Puech","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjBYZ2jCEfVY61tMOjfGATwIpwvX368uNMu2bf4Xg=s64","userId":"01637125792908796850"}},"outputId":"b00b7315-ea0b-4629-8b55-9dcce5c8abec"},"source":["class RnnModel(tf.keras.Model):\n","\n","    def __init__(self, vocab_size):\n","        super(RnnModel, self).__init__()\n","        # Convolutions\n","        self.one_hot = OneHot(len(vocab))\n","\n","    def call(self, inputs):\n","        output = self.one_hot(inputs)\n","        return output\n","\n","batch_inputs, batch_targets = next(gen_batch(inputs, targets, 50, 32))\n","\n","print(batch_inputs.shape)\n","\n","model = RnnModel(len(vocab))\n","output = model.predict(batch_inputs)\n","\n","print(output.shape)\n","\n","#print(output)\n","\n","print(\"Input letter is:\", batch_inputs[0][0])\n","print(\"One hot representation of the letter\", output[0][0])\n","\n","#assert(output[int(batch_inputs[0][0])]==1)\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["(32, 50)\n","(32, 50, 34)\n","Input letter is: 20.0\n","One hot representation of the letter [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.\n"," 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"4nTM6i_0TDeu"},"source":["# Set up the model"]},{"cell_type":"markdown","metadata":{"id":"cAfjdMQWTDeu"},"source":["<img src=\"./images/architecture_rnn.png\" width=\"400px\" ></img>"]},{"cell_type":"code","metadata":{"id":"DeKsZ4ggTDeu"},"source":["vocab_size = len(vocab)\n","\n","### Creat the layers\n","\n","# Set the input of the model\n","tf_inputs = tf.keras.Input(shape=(None,), batch_size=64)\n","# Convert each value of the  input into a one encoding vector\n","one_hot = OneHot(len(vocab))(tf_inputs)\n","# Stack LSTM cells\n","rnn_layer1 = tf.keras.layers.LSTM(128, return_sequences=True, stateful=True)(one_hot)\n","rnn_layer2 = tf.keras.layers.LSTM(128, return_sequences=True, stateful=True)(rnn_layer1)\n","# Create the outputs of the model\n","hidden_layer = tf.keras.layers.Dense(128, activation=\"relu\")(rnn_layer2)\n","outputs = tf.keras.layers.Dense(vocab_size, activation=\"softmax\")(hidden_layer)\n","\n","### Setup the model\n","model = tf.keras.Model(inputs=tf_inputs, outputs=outputs)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"t-PlASWwTDev"},"source":["## Check if we can reset the RNN cells"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":911},"id":"K3ERZsgUTDev","executionInfo":{"status":"error","timestamp":1615382865475,"user_tz":-60,"elapsed":897,"user":{"displayName":"Axel Puech","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjBYZ2jCEfVY61tMOjfGATwIpwvX368uNMu2bf4Xg=s64","userId":"01637125792908796850"}},"outputId":"fbb23d4a-260a-4f51-fc20-5de5f7b288e0"},"source":["# Star by resetting the cells of the RNN\n","model.reset_states()\n","\n","# Get one batch\n","batch_inputs, batch_targets = next(gen_batch(inputs, targets, 50, 64))\n","print(batch_inputs.shape)\n","# Make a first prediction\n","outputs = model.predict(batch_inputs)\n","first_prediction = outputs[0][0]\n","\n","# Reset the states of the RNN states\n","model.reset_states()\n","\n","# Make an other prediction to check the difference\n","outputs = model.predict(batch_inputs)\n","second_prediction = outputs[0][0]\n","\n","# Check if both prediction are equal\n","assert(set(first_prediction)==set(second_prediction))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["(64, 50)\n","WARNING:tensorflow:Model was constructed with shape (64, None) for input KerasTensor(type_spec=TensorSpec(shape=(64, None), dtype=tf.float32, name='input_1'), name='input_1', description=\"created by layer 'input_1'\"), but it was called on an input with incompatible shape (32, 50).\n"],"name":"stdout"},{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-25-cf67a0077e3f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_inputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Make a first prediction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mfirst_prediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1627\u001b[0m           \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1628\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_predict_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1629\u001b[0;31m             \u001b[0mtmp_batch_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1630\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1631\u001b[0m               \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    860\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 862\u001b[0;31m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    863\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    864\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2939\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2940\u001b[0m       (graph_function,\n\u001b[0;32m-> 2941\u001b[0;31m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0m\u001b[1;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[1;32m   2943\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3356\u001b[0m               call_context_key in self._function_cache.missed):\n\u001b[1;32m   3357\u001b[0m             return self._define_function_with_shape_relaxation(\n\u001b[0;32m-> 3358\u001b[0;31m                 args, kwargs, flat_args, filtered_flat_args, cache_key_context)\n\u001b[0m\u001b[1;32m   3359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3360\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_define_function_with_shape_relaxation\u001b[0;34m(self, args, kwargs, flat_args, filtered_flat_args, cache_key_context)\u001b[0m\n\u001b[1;32m   3278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3279\u001b[0m     graph_function = self._create_graph_function(\n\u001b[0;32m-> 3280\u001b[0;31m         args, kwargs, override_flat_arg_shapes=relaxed_arg_shapes)\n\u001b[0m\u001b[1;32m   3281\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marg_relaxed\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrank_only_cache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3282\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3204\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3205\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3206\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   3207\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3208\u001b[0m         \u001b[0mfunction_spec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_spec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    988\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    989\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 990\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    991\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    992\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    632\u001b[0m             \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 634\u001b[0;31m           \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    635\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    975\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    976\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 977\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    978\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    979\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: in user code:\n\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1478 predict_function  *\n        return step_function(self, iterator)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1468 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py:1259 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py:2730 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py:3417 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1461 run_step  **\n        outputs = model.predict_step(data)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1434 predict_step\n        return self(x, training=False)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer.py:1012 __call__\n        outputs = call_fn(inputs, *args, **kwargs)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/functional.py:425 call\n        inputs, training=training, mask=mask)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/functional.py:560 _run_internal_graph\n        outputs = node.layer(*args, **kwargs)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/layers/recurrent.py:660 __call__\n        return super(RNN, self).__call__(inputs, **kwargs)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer.py:998 __call__\n        input_spec.assert_input_compatibility(self.input_spec, inputs, self.name)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/input_spec.py:274 assert_input_compatibility\n        ', found shape=' + display_shape(x.shape))\n\n    ValueError: Input 0 is incompatible with layer lstm: expected shape=(64, None, 34), found shape=(32, 50, 34)\n"]}]},{"cell_type":"markdown","metadata":{"id":"kwuscP4cTDev"},"source":["## Set the loss and objectives"]},{"cell_type":"code","metadata":{"id":"5MbyXw_fTDev"},"source":["loss_object = tf.keras.losses.SparseCategoricalCrossentropy()\n","optimizer = tf.keras.optimizers.Adam(lr=0.001)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"SLLbIdsUTDev"},"source":["## Set some metrics to track the progress of the training"]},{"cell_type":"code","metadata":{"id":"Bhey-zFeTDew"},"source":["# Loss\n","train_loss = tf.keras.metrics.Mean(name='train_loss')\n","# Accuracy\n","train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='train_accuracy')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"NHr-P5K8TDew"},"source":["## Set the train method and the predict method in graph mode"]},{"cell_type":"code","metadata":{"id":"dm1ZIux8TDew"},"source":["@tf.function\n","def train_step(inputs, targets):\n","    with tf.GradientTape() as tape:\n","        # Make a prediction on all the batch\n","        predictions = model(inputs)\n","        # Get the error/loss on these predictions\n","        loss = loss_object(targets, predictions)\n","    # Compute the gradient which respect to the loss\n","    gradients = tape.gradient(loss, model.trainable_variables)\n","    # Change the weights of the model\n","    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n","    # The metrics are accumulate over time. You don't need to average it yourself.\n","    train_loss(loss)\n","    train_accuracy(targets, predictions)\n","\n","@tf.function\n","def predict(inputs):\n","    # Make a prediction on all the batch\n","    predictions = model(inputs)\n","    return predictions"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Gka7rXNtTDex"},"source":["# Train the model"]},{"cell_type":"code","metadata":{"id":"sAcG7_ukTDex"},"source":["model.reset_states()\n","\n","for epoch in range(4000):\n","    for batch_inputs, batch_targets in gen_batch(inputs, targets, 100, 64, noise=13):\n","        train_step(batch_inputs, batch_targets)\n","    template = '\\r Epoch {}, Train Loss: {}, Train Accuracy: {}'\n","    print(template.format(epoch, train_loss.result(), train_accuracy.result()*100), end=\"\")\n","    model.reset_states()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_FeJn-MTTDex"},"source":["## Save the model"]},{"cell_type":"code","metadata":{"id":"4Ng8WyCCTDey"},"source":["import json\n","model.save(\"model_rnn.h5\")\n","\n","with open(\"model_rnn_vocab_to_int\", \"w\") as f:\n","    f.write(json.dumps(vocab_to_int))\n","with open(\"model_rnn_int_to_vocab\", \"w\") as f:\n","    f.write(json.dumps(int_to_vocab))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"F6gP6PHDTDey"},"source":["# Generate some text"]},{"cell_type":"code","metadata":{"id":"ap7SJBr_TDey"},"source":["import random\n","\n","model.reset_states()\n","\n","size_poetries = 300\n","\n","poetries = np.zeros((64, size_poetries, 1))\n","sequences = np.zeros((64, 100))\n","for b in range(64):\n","    rd = np.random.randint(0, len(inputs) - 100)\n","    sequences[b] = inputs[rd:rd+100]\n","\n","for i in range(size_poetries+1):\n","    if i > 0:\n","        poetries[:,i-1,:] = sequences\n","    softmax = predict(sequences)\n","    # Set the next sequences\n","    sequences = np.zeros((64, 1))\n","    for b in range(64):\n","        argsort = np.argsort(softmax[b][0])\n","        argsort = argsort[::-1]\n","        # Select one of the strongest 4 proposals\n","        sequences[b] = argsort[0]\n","\n","for b in range(64):\n","    sentence = \"\".join([int_to_vocab[i[0]] for i in poetries[b]])\n","    print(sentence)\n","    print(\"\\n=====================\\n\")\n","        "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vAeZ3QICTDey"},"source":["import json\n","\n","with open(\"model_rnn_vocab_to_int\", \"r\") as f:\n","    vocab_to_int = json.loads(f.read())\n","with open(\"model_rnn_int_to_vocab\", \"r\") as f:\n","    int_to_vocab = json.loads(f.read())\n","    int_to_vocab = {int(key):int_to_vocab[key] for key in int_to_vocab}\n","\n","model.load_weights(\"model_rnn.h5\")"],"execution_count":null,"outputs":[]}]}