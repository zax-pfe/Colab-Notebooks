{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"01-RNN-Exemple-Time-Series.ipynb","provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"jqsUDXiPgXjO"},"source":["# RNN Exemple pour les Séries Temporelles"]},{"cell_type":"code","metadata":{"id":"UQK7Of4JgLFf"},"source":["import pandas as pd\n","import numpy as np\n","\n","import matplotlib.pyplot as plt"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"FDpq1LUEgmzK"},"source":["## Données\n","\n","Publication : Ventes mensuelles anticipées pour le commerce de détail et les services de restauration  \n","\n","Unités :  Millions de dollars, pas d'ajustement de saisonnalité\n","\n","Fréquence :  Mensuelle\n","\n","La valeur pour le mois le plus récent est une estimation anticipée qui est basée sur les données d'un sous-échantillon d'entreprises de l'enquête mensuelle sur le commerce de détail, plus importante. L'estimation anticipée sera remplacée au cours des mois suivants par des estimations révisées issues de l'enquête mensuelle sur le commerce de détail, plus vaste. Les séries associées de l'enquête mensuelle sur le commerce de détail sont disponibles à l'adresse suivante : https://fred.stlouisfed.org/series/MRTSSM448USN\n","\n","Des informations sur l'enquête mensuelle anticipée sur les ventes au détail sont disponibles sur le site web du recensement à l'adresse suivante : https://www.census.gov/retail/marts/about_the_surveys.html\n","\n","Citation suggérée :\n","U.S. Census Bureau, Advance Retail Sales : Clothing and Clothing Accessory Stores [RSCCASN], extrait de FRED, Federal Reserve Bank of St. Louis ; https://fred.stlouisfed.org/series/RSCCASN, 16 novembre 2019.\n","\n","https://fred.stlouisfed.org/series/RSCCASN"]},{"cell_type":"code","metadata":{"id":"VX-rtHYwgi97","colab":{"base_uri":"https://localhost:8080/","height":370},"executionInfo":{"status":"error","timestamp":1615459465826,"user_tz":-60,"elapsed":1551,"user":{"displayName":"Axel Puech","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjBYZ2jCEfVY61tMOjfGATwIpwvX368uNMu2bf4Xg=s64","userId":"01637125792908796850"}},"outputId":"60993846-cbd0-4c7a-9738-e6f39c702343"},"source":["df = pd.read_csv('RSCCASN.csv',index_col='DATE',parse_dates=True)"],"execution_count":null,"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-2-52db749eb69a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'RSCCASN.csv'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mindex_col\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'DATE'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mparse_dates\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    686\u001b[0m     )\n\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 688\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    689\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 454\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    946\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    947\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 948\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    950\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1178\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1180\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1181\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   2008\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2009\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2010\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2011\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2012\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n","\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'RSCCASN.csv'"]}]},{"cell_type":"code","metadata":{"id":"tXtvEUexhoUs"},"source":["df.head()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YCE-tFIUhqg5"},"source":["df.columns = ['Sales']"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XbNS86O-hsR7"},"source":["df.plot(figsize=(12,8))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"w657Bi3HhwLP"},"source":["## Répartition Entraînement / Test"]},{"cell_type":"code","metadata":{"id":"3ST5Biwphtxu"},"source":["len(df)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hkjNwhoHiF_H"},"source":["Les données sont mensuelles, prévoyons un an et demi dans le futur."]},{"cell_type":"code","metadata":{"id":"eXiG61ijh0Ud"},"source":["len(df)- 18"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hM78Kja1iJFa"},"source":["test_size = 18"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"SE-paG3aiKZZ"},"source":["test_ind = len(df)- test_size"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"30I74aXjiLvi"},"source":["train = df.iloc[:test_ind]\n","test = df.iloc[test_ind:]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nD1tq7p3iNTj"},"source":["train"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hUqL4FmfiO2t"},"source":["test"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ezg7DS9HiST6"},"source":["## Mise à l'échelle des données"]},{"cell_type":"code","metadata":{"id":"GJ-pTJMziQOx"},"source":["from sklearn.preprocessing import MinMaxScaler"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"TR3P3rYRiXm7"},"source":["scaler = MinMaxScaler()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"RF2MX57UiZH9"},"source":["# Si warning, ignorez le, cest juste une conversion en float\n","# Adapter uniquement aux données d'entraînement, sinon nous trichons en supposant des informations sur les données test\n","scaler.fit(train)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_UcbEzGvic2h"},"source":["scaled_train = scaler.transform(train)\n","scaled_test = scaler.transform(test)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"pW9g5AVQimsB"},"source":["## Générateur de séries temporelles\n","\n","Cette classe examine une série de points de données recueillis à\n","des intervalles égaux, ainsi que des paramètres de séries temporelles tels stride, length , etc., afin de produire des lots pour\n","l'entraînement/validation.\n","\n","#### Arguments\n","    data: Indexable generator (such as list or Numpy array)\n","        containing consecutive data points (timesteps).\n","        The data should be at 2D, and axis 0 is expected\n","        to be the time dimension.\n","    targets: Targets corresponding to timesteps in `data`.\n","        It should have same length as `data`.\n","    length: Length of the output sequences (in number of timesteps).\n","    sampling_rate: Period between successive individual timesteps\n","        within sequences. For rate `r`, timesteps\n","        `data[i]`, `data[i-r]`, ... `data[i - length]`\n","        are used for create a sample sequence.\n","    stride: Period between successive output sequences.\n","        For stride `s`, consecutive output samples would\n","        be centered around `data[i]`, `data[i+s]`, `data[i+2*s]`, etc.\n","    start_index: Data points earlier than `start_index` will not be used\n","        in the output sequences. This is useful to reserve part of the\n","        data for test or validation.\n","    end_index: Data points later than `end_index` will not be used\n","        in the output sequences. This is useful to reserve part of the\n","        data for test or validation.\n","    shuffle: Whether to shuffle output samples,\n","        or instead draw them in chronological order.\n","    reverse: Boolean: if `true`, timesteps in each output sample will be\n","        in reverse chronological order.\n","    batch_size: Number of timeseries samples in each batch\n","        (except maybe the last one)."]},{"cell_type":"code","metadata":{"id":"5J8JcAxdifxW"},"source":["from tensorflow.keras.preprocessing.sequence import TimeseriesGenerator"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"A4pvEIlyipSR"},"source":["# Redéfinissons pour obtenir 12 mois en arrière et prédisons le mois suivant\n","length = 12\n","generator = TimeseriesGenerator(scaled_train, scaled_train, length=length, batch_size=1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9mPvA9NUitto"},"source":["# À quoi ressemble le premier batch ?\n","X,y = generator[0]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qCzT_-GOi1FQ"},"source":["print(f\"Compte tenu du tableau suivant : \\n {X.flatten()}\")\n","print(f'Cela prédit ce y : \\n {y}')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"S3Cvrokdi7eL"},"source":["## Création du Modèle"]},{"cell_type":"code","metadata":{"id":"uv-TxArpi46I"},"source":["from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense, LSTM"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VqautyFKi-NQ"},"source":["# Nous n'utilisons qu'une seule feature dans notre série temporelle\n","n_features = 1"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qijx_NaUjDFl"},"source":["# définir le modèle\n","model = Sequential()\n","model.add(LSTM(100, activation='relu', input_shape=(length, n_features)))\n","model.add(Dense(1))\n","model.compile(optimizer='adam', loss='mse')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-d4e8ZaUjF2m"},"source":["model.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"z-ZLVNzBkIqD"},"source":["## EarlyStopping et création d'un Générateur de Validation\n","\n","REMARQUE : la taille de l'ensemble de données scaled_test DOIT être supérieure à la longueur choisie pour vos batchs. Regardez la vidéo pour plus d'informations à ce sujet."]},{"cell_type":"code","metadata":{"id":"s3KJDPF6kCBv"},"source":["from tensorflow.keras.callbacks import EarlyStopping"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mIOTXEXJkVk6"},"source":["early_stop = EarlyStopping(monitor='val_loss',patience=2)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"aB0sAl-fkW9f"},"source":["validation_generator = TimeseriesGenerator(scaled_test,scaled_test, length=length, batch_size=1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9LaCxnbqkZQ-"},"source":["# ajustement du modèle\n","model.fit(generator,epochs=20,\n","                    validation_data=validation_generator,\n","                   callbacks=[early_stop])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ODUkXYKckehb"},"source":["losses = pd.DataFrame(model.history.history)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vgEdKGQ1koVg"},"source":["losses.plot()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xUJLuixgkzvF"},"source":["## Évaluation sur les données de test"]},{"cell_type":"code","metadata":{"id":"gKm7PysHkuZ-"},"source":["first_eval_batch = scaled_train[-length:]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bp6FFKOhlB_W"},"source":["first_eval_batch = first_eval_batch.reshape((1, length, n_features))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fuI2aLwGlGZG"},"source":["model.predict(first_eval_batch)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"k0-0GnEKl7wP"},"source":["scaled_test[0]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qXJYNOEVmDpp"},"source":["Mettons maintenant cette logique dans une boucle for pour prédire l'avenir pour toute la gamme de test.\n","\n","----"]},{"cell_type":"markdown","metadata":{"id":"FJI8yeBSmHEe"},"source":["**NOTE : Soyez attentif ici aux sorties et aux dimensions. Ajoutez vos propres commandes print() pour voir ce qui se passe vraiment !**"]},{"cell_type":"code","metadata":{"id":"Y3A7HXGXl-m3"},"source":["test_predictions = []\n","\n","first_eval_batch = scaled_train[-length:]\n","current_batch = first_eval_batch.reshape((1, length, n_features))\n","\n","for i in range(len(test)):\n","    \n","    # obtenir la prédiction avec 1 timestamp d'avance ([0] pour ne saisir que le nombre au lieu de [array])\n","    current_pred = model.predict(current_batch)[0]\n","    \n","    # stocker la prédiction\n","    test_predictions.append(current_pred) \n","    \n","    # mise à jour du batch pour inclure maintenant la prédiction et supprimer la première valeur\n","    current_batch = np.append(current_batch[:,1:,:],[[current_pred]],axis=1)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"I_mH0q3snJfK"},"source":["## Transformations inverses et Comparaison"]},{"cell_type":"code","metadata":{"id":"wQ-53jaenJ8R"},"source":["true_predictions = scaler.inverse_transform(test_predictions)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"RuJ2Yx85nMRd"},"source":["# Ignorez le warning\n","test['Predictions'] = true_predictions"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2RqcpxH2nSZJ"},"source":["test"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZegOu1I2nU05"},"source":["test.plot(figsize=(12,8))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Nqgrcpxena14"},"source":["## Ré-Entraînement et Prévision"]},{"cell_type":"code","metadata":{"id":"g863-NLlnWpn"},"source":["full_scaler = MinMaxScaler()\n","scaled_full_data = full_scaler.fit_transform(df)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Z9sOlDYEnf1y"},"source":["length = 12 # Longueur des séquences de sortie (en nombre de pas temporel)\n","generator = TimeseriesGenerator(scaled_full_data, scaled_full_data, length=length, batch_size=1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"e_liyUHNnj32"},"source":["model = Sequential()\n","model.add(LSTM(100, activation='relu', input_shape=(length, n_features)))\n","model.add(Dense(1))\n","model.compile(optimizer='adam', loss='mse')\n","\n","\n","# ajustement du modèle\n","model.fit(generator,epochs=8)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XdEAuJHxnpMg"},"source":["forecast = []\n","# Remplacez les périodes par la durée de prévision que vous souhaitez\n","periods = 12\n","\n","first_eval_batch = scaled_full_data[-length:]\n","current_batch = first_eval_batch.reshape((1, length, n_features))\n","\n","for i in range(periods):\n","    \n","    # obtenir la prédiction avec 1 timestamp d'avance ([0] pour ne saisir que le nombre au lieu de [array])\n","    current_pred = model.predict(current_batch)[0]\n","    \n","    # stocker la prédiction\n","    forecast.append(current_pred) \n","    \n","    # mise à jour du batch pour inclure maintenant la prédiction et supprimer la première valeur\n","    current_batch = np.append(current_batch[:,1:,:],[[current_pred]],axis=1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"J9-IZvtBn3NL"},"source":["forecast = full_scaler.inverse_transform(forecast)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"IEZZdIc7n8_D"},"source":["### Création d'un nouvel index TimeStamp avec Pandas"]},{"cell_type":"code","metadata":{"id":"sDXO2v6pn5IO"},"source":["df"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"KfL5CEcEoC1n"},"source":["forecast_index = pd.date_range(start='2019-11-01',periods=periods,freq='MS')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mzSk7NVVoJTx"},"source":["forecast_df = pd.DataFrame(data=forecast,index=forecast_index,\n","                           columns=['Forecast'])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5JQdHHhToKww"},"source":["forecast_df"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7IyZMFfqoMLd"},"source":["df.plot()\n","forecast_df.plot()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1qiGgsVuoS-D"},"source":["### Unir les graphiques avec Pandas\n","\n","https://stackoverflow.com/questions/13872533/plot-different-dataframes-in-the-same-figure"]},{"cell_type":"code","metadata":{"id":"rflmaC5SoN3H"},"source":["ax = df.plot()\n","forecast_df.plot(ax=ax)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Q8K-Tf-3ok11"},"source":["ax = df.plot()\n","forecast_df.plot(ax=ax)\n","plt.xlim('2018-01-01','2020-12-01')"],"execution_count":null,"outputs":[]}]}