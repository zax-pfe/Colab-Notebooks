{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"V2_variables_attention.ipynb","provenance":[],"collapsed_sections":["PLhvt0cVZ5f0"]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.5"}},"cells":[{"cell_type":"code","metadata":{"id":"FpeH-aYoa2DB"},"source":["import numpy as np\n","import sys # Permet de connaitre la version de python\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","import tensorflow as tf\n","import os\n","from collections import Counter"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"at15Or58Z5fm"},"source":["#!pip install tqdm"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"iz6_SV1PZ5fm"},"source":["from tqdm import tqdm # Permet d'afficher les barres de chargement"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"14BUsK9TZ5fn","colab":{"base_uri":"https://localhost:8080/","height":229},"executionInfo":{"status":"error","timestamp":1630915634070,"user_tz":-120,"elapsed":4,"user":{"displayName":"Axel","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiSgb-gUyVm7Dftsq1qnzVUodf0QJgXJ6Q7_nvF1g=s64","userId":"01637125792908796850"}},"outputId":"56e87393-3e33-41c4-ce40-06eda773db7d"},"source":["with open(\"bdd.txt\",\"r\") as f:\n","    num_folder = len(f.readlines())\n","with open(\"sbt.txt\",\"r\") as f:\n","    if (len(f.readlines()) != num_folder):\n","        error(\"[ERROR] number of BDD function does not match BDD number\")\n","print(\"Number of function/Foler = \", num_folder)  # This would give length of files."],"execution_count":null,"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-8-a990fa8c5e7a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"bdd.txt\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"r\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mnum_folder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadlines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"sbt.txt\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"r\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadlines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mnum_folder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0merror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"[ERROR] number of BDD function does not match BDD number\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'bdd.txt'"]}]},{"cell_type":"code","metadata":{"id":"--heg9JYZ5fo"},"source":["print(\"Get the bdd and sbt list via the bdd.txt & sbt.txt\")\n","with open(\"bdd.txt\") as f:\n","    tmp_bdd = f.read()\n","bdd = tmp_bdd.split(\"\\n\")\n","\n","with open(\"sbt.txt\") as f:\n","    tmp_sbt = f.read()\n","sbt = tmp_sbt.split(\"\\n\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"QG2Dv6fhZ5fo"},"source":["# Séparation variables / template\n","\n","Afin de créer une matrice d'encodage, il faut dans un premier temps determiner quelles seront les dimensions de cette matrice. Comme nous encodons en integer encoding les dimmensions des matrices vont etre les suivantes : ( nombre de fichiers, nombre de mot max par fichier ) "]},{"cell_type":"markdown","metadata":{"id":"HsXAhSjoZ5fo"},"source":["Les counters permettent de compter le nombre d'occurence de chaque mot, ces données sont ensuite utilisé pour determiner si un mot appartient a la template ou si c est une variable."]},{"cell_type":"code","metadata":{"id":"7LE8LwldZ5fp"},"source":["bdd_counter =Counter([word for sentence in bdd for word in sentence.split(' ')])\n","sbt_counter =Counter([word for sentence in sbt for word in sentence.split(' ')])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"R4JgUfxRZ5fp"},"source":["Une fois le nombre d'occurence de chaque mot calculé, il faut ensuite regarder quels mots sont les plus souvent répété. J'ai considéré que sur 5000 fichiers, si un mot apparait plus de 3500 fois, alors nous pouvons le considerer comme appartenant a la template. "]},{"cell_type":"code","metadata":{"id":"cwdbLYSmZ5fp"},"source":["'''\n","common_words_sbt = []\n","for word in sbt_counter:\n","    occurence = sbt_counter[word]\n","    if occurence > 3500:\n","        common_words_sbt.append(word)\n","print(\"common_words_sbt :\\n\",common_words_sbt)\n","'''"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-kR6TE6lZ5fq"},"source":["'''\n","common_words_bdd = []\n","for word in bdd_counter:\n","    occurence= bdd_counter[word]\n","    if occurence > 3500:\n","        common_words_bdd.append(word)\n","print(\"common_words_bdd :\\n\",common_words_bdd)\n","'''"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kTbfhPV3Z5fq"},"source":["common_words_sbt=['', '(', 'MethodDeclaration', 'Modifier', 'public', ')',\n","                  'static', 'SimpleName', 'Parameter', 'PrimitiveType', 'int', 'boolean', 'BlockStmt',\n","                  'ExpressionStmt', 'VariableDeclarationExpr', 'VariableDeclarator', 'IntegerLiteralExpr',\n","                  'res', 'BinaryExpr', 'NameExpr', 'IfStmt', 'ReturnStmt', 'BooleanLiteralExpr', 'true',\n","                  'false', 'UnaryExpr']\n","common_words_bdd =  ['Feature:', 'Check', 'the', '', '#', 'result', 'to', 'True', 'Scenario:', 'Given', '=',\n","                     'and', 'When', 'i', 'call', 'Then', 'should', 'be', 'False']"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"B0EZ5T0KZ5fr"},"source":["'''\n","def return_common_words(counter):\n","    common_words = []\n","    for word in counter:\n","        print(' --> ',word)\n","        occurence = counter[word]\n","        if occurence > 3500:\n","            common_words.append(word)\n","    return common_words\n","    \n","\n","common_words_bdd = return_common_words(bdd_counter)\n","common_words_sbt = return_common_words(sbt_counter)\n"," '''   "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"fPuPmMqWZ5fr"},"source":["# ---------------------------------------------------------------------------------------------------------------\n","\n","# Listing des variables "]},{"cell_type":"markdown","metadata":{"id":"GIzqAvtDZ5fs"},"source":["La fonction suivante permet de renvoyer deux tableaux :\n","\n","Un premier : arr, a deux dimensions, qui permet de lister pour chaque code ses variables, ce code sera encodé puis donné au modèle.\n","        \n","le deuxieme : var, permet de lister toutes les variables présent dans tout les codes pour pouvoir ensuite creer un vocabulaire\n","    "]},{"cell_type":"code","metadata":{"id":"E7qrGDDeZ5fs"},"source":["def return_listing(text,common_words): \n","    arr= [[] for _ in range(num_folder)] #pour calculer la taille max de toute les variables réunies \n","    var = [] # pour creer un vocabulaire \n","    for i,sentence in  enumerate(text):\n","        text_split = sentence.split( ' ')\n","        for j,word in enumerate (text_split):\n","            if word not in common_words:\n","                arr[i].append(word)\n","                var.append(word) \n","    return arr, var"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"46o7IeYqZ5fs"},"source":["La fonction suivante permet de retouner pour un unique code SBT la liste des variables et mettre dans le format suivant : \n","var1/var2/var3"]},{"cell_type":"code","metadata":{"id":"cXWaU5r2Z5ft"},"source":["def return_variables_unique(text): \n","    var = [] # tableau contenant les variables separées par /, ex : var1/var2/...\n","    text_split = text.split(' ')\n","    for i,word in enumerate (text_split):\n","        if word not in common_words_sbt:\n","            var.append(word)\n","            var.append('/')\n","    return ''.join(var)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YZIvDXb3Z5ft"},"source":["variables_unique = return_variables_unique(sbt[0])\n","#print(variables_unique)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"P_AYVbq6Z5ft"},"source":["arr_var_bdd, variables_bdd = return_listing(bdd,common_words_bdd)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"FifSCuwCZ5fu"},"source":["arr_var_sbt,variables_sbt= return_listing(sbt,common_words_sbt)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"w4A7Af1BZ5fu"},"source":["Conversion des variables en sequence de variables séparées par / ( var1/var2/var3 ... ) "]},{"cell_type":"code","metadata":{"id":"H_AZRaYaZ5fu"},"source":["def return_var_list(variables_arr):    \n","    varlist = []\n","\n","    for vars in variables_arr:\n","        temp_varlist = []\n","        for var in vars:\n","            temp_varlist.append(var)\n","            temp_varlist.append('/')\n","        varlist.append(''.join(temp_varlist))\n","    return varlist"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3rYL2Nc9Z5fu"},"source":["On cree nos séquences de variables avec la fonction précédente"]},{"cell_type":"code","metadata":{"id":"4xGdFWhdZ5fv"},"source":["varlist_bdd = return_var_list(arr_var_bdd)\n","varlist_sbt = return_var_list(arr_var_sbt)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Ay56SGK2Z5fv"},"source":["# Calcul du nombre de var max par code et du nombre de lettre total"]},{"cell_type":"code","metadata":{"id":"rrBbfjvrZ5fv"},"source":["# Pour des raisons qe j'ignore cette cellule creer une erreur losqu'elle est exécutée depuis 'V2_union' avec Jupyter.\n","# Les résultats obtenus par cette fonciton seront donc entrés en brut sur jupyter pour que le programme puis s'executer. \n","\n","def return_nb_var_maxlen_var(arr):\n","    all_len = []\n","    nb_var = []\n","    for words in arr:\n","        temp_len = 0\n","        for j,word in enumerate(words):\n","            for i,char in enumerate(word):\n","              do_nothing = 0\n","            temp_len=temp_len+i+1\n","        nb_var.append(j+1)\n","        all_len.append(temp_len)\n","    return max(nb_var), max(all_len)\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"RcFdJ7ndZ5fv"},"source":["# Creation d'un vocabulaire pour les variables "]},{"cell_type":"markdown","metadata":{"id":"Heg14WJHZ5fv"},"source":["La cellule ci dessous permet de lister chaque caractere different"]},{"cell_type":"code","metadata":{"id":"VzFc6z_9Z5fw"},"source":["vocab_variables_bdd = {l for char in variables_bdd for l in char}\n","vocab_variables_sbt = {l for char in variables_sbt for l in char}"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"RivDDPnEZ5fw"},"source":["Nous séparons chacune des variables par un \"/\" et nous allons ensuite rajouter des start of sentence token et end of sentence token au debut et a la fin de chacune de nos sequences de variables, ces token sont initialement absents du vocabulaire, il faut donc les rajouter manuelement "]},{"cell_type":"code","metadata":{"id":"EqHwUi2VZ5fw"},"source":["vocab_variables_bdd.add('/')\n","vocab_variables_bdd.add('sostoken ')\n","vocab_variables_bdd.add(' eostoken')\n","\n","vocab_variables_sbt.add('/')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"NOQQ4xgXZ5fw"},"source":["Nous allons maintenant créer des dictionnnaires, c'est à dire associer à chaque caractere un nombre. La cellule suivante creer deux dictionnaire pour chaque type de code ( BDD,SBT) qui nous premettent avec un caractere d'acceder à son index et inversement."]},{"cell_type":"code","metadata":{"id":"ibsRb4HtZ5fw"},"source":["char_to_ind_bdd = {char : ind for ind,char in enumerate(vocab_variables_bdd)}\n","ind_to_char_bdd = {ind : char for ind,char in enumerate(vocab_variables_bdd)}"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"KDnhwF8VZ5fw"},"source":["char_to_ind_sbt = {char : ind for ind,char in enumerate(vocab_variables_sbt)}\n","ind_to_char_sbt = {ind : char for ind,char in enumerate(vocab_variables_sbt)}"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"WpPkzCTiZ5fx"},"source":["# Valeurs encodage BDD"]},{"cell_type":"code","metadata":{"id":"j68zz4NGZ5fx","outputId":"813b5c3c-e484-41c2-da7e-06f2fd51da18"},"source":["#Resultat entrés en brut car la fonction 'return_nb_var_maxlen_var' ne s'execute par depuis 'V2_union'\n","#number_variables_bdd = 13\n","#len_chain= 92\n","number_variables_bdd, len_chain = return_nb_var_maxlen_var(arr_var_bdd)\n","number_char_variables_bdd = len(vocab_variables_bdd)\n","len_total_chain_bdd = number_variables_bdd+len_chain+1\n","\n","'''\n","print('nombre total de bdd :', num_folder)\n","print('nombre total de variables par fichier bdd:', number_variables_bdd)\n","print('taille de la chaine :',len_chain)\n","print('nombre total de char dans la chaine avec / :',len_total_chain_bdd)\n","print('nombre de char differents bdd :', number_char_variables_bdd)\n","\n","'''"],"execution_count":null,"outputs":[{"data":{"text/plain":["\"\\nprint('nombre total de bdd :', num_folder)\\nprint('nombre total de variables par fichier bdd:', number_variables_bdd)\\nprint('taille de la chaine :',len_chain)\\nprint('nombre total de char dans la chaine avec / :',len_total_chain_bdd)\\nprint('nombre de char differents bdd :', number_char_variables_bdd)\\n\""]},"execution_count":24,"metadata":{},"output_type":"execute_result"}]},{"cell_type":"markdown","metadata":{"id":"M8p6MazcZ5fx"},"source":["# Valeur encodage SBT"]},{"cell_type":"code","metadata":{"id":"7ThTZKSvZ5fx","outputId":"35c425fc-fd76-46c1-a968-35478df41ea0"},"source":["#Resultat entrés en brut car la fonction 'return_nb_var_maxlen_var' ne s'execute par depuis 'V2_union'\n","#number_variables_sbt=22\n","#len_chain_sbt=50\n","number_variables_sbt, len_chain_sbt = return_nb_var_maxlen_var(arr_var_sbt)\n","number_char_variables_sbt = len(vocab_variables_sbt)\n","len_total_chain_sbt = number_variables_sbt+len_chain_sbt+1\n","\n","'''\n","print('nombre total de bdd :', num_folder)\n","print('nombre total de variables par fichier sbt:', number_variables_sbt)\n","print('taille de la chaine :',len_chain_sbt)\n","print('nombre total de char dans la chaine avec / :',len_total_chain_sbt)\n","print('nombre de char differents sbt :', number_char_variables_sbt)\n","'''"],"execution_count":null,"outputs":[{"data":{"text/plain":["\"\\nprint('nombre total de bdd :', num_folder)\\nprint('nombre total de variables par fichier sbt:', number_variables_sbt)\\nprint('taille de la chaine :',len_chain_sbt)\\nprint('nombre total de char dans la chaine avec / :',len_total_chain_sbt)\\nprint('nombre de char differents sbt :', number_char_variables_sbt)\\n\""]},"execution_count":25,"metadata":{},"output_type":"execute_result"}]},{"cell_type":"markdown","metadata":{"id":"LWXDJcLnZ5fy"},"source":["# Description du fonctionnement du modèle."]},{"cell_type":"markdown","metadata":{"id":"8z356r_iZ5fy"},"source":["On convertit nos sequences de variables en dataframe puis nous allosn.\n","Nous créons en plus deux nouvelles colonne dans notre dataframe, bdd_input et bdd_label. "]},{"cell_type":"markdown","metadata":{"id":"d2gTtr4_Z5fy"},"source":["Nous allons donc donner au modele pour son entrainement en entrée le SBT et BDD_input, et en sortie le BDD_label que nous allons dans un premier temps convertir en numpy array."]},{"cell_type":"markdown","metadata":{"id":"EYPU82SqZ5fy"},"source":["![image.png](attachment:image.png)"]},{"cell_type":"markdown","metadata":{"id":"0szXu9l1Z5fy"},"source":["le fonctionnement d'un tel model est le suivant : \n","Dans un premier temps les informations contenues dans le SBT sont condensée et transformée en un vecteur par l'encoder, ce vecteur est appelé le context vector. \n","\n","Le réseau de neuronne récurent qui prend le BDD_input en entrée et le BDD_Label en sortie, nous permet d'indiquer au modele qu'a la suite d'un certain mot, par exemple \"je\", il doit prédire \"suis\".\n","\n","La couche d'attention permet au modele de se focaliser sur certaines partie de la sequence en entrée afin de prédire par exemple le début de la séquence en sortie.\n","\n","En superposant ces information, le modele est donc capable de savoir que pour un contexte \" i am a student\" et a la suite de \"< s >\" il doit prédire \" Je \" \n","\n","< s > représente notre start of sentence token : sostoken"]},{"cell_type":"code","metadata":{"id":"f1yoOkBGZ5fy","outputId":"47df76bc-da66-41bf-8af3-f2e33c2ad0a0"},"source":["df = pd.DataFrame(varlist_bdd, columns=['bdd'])\n","df['sbt'] = varlist_sbt\n","df['bdd_input'] = varlist_bdd\n","df['bdd_label'] = varlist_bdd\n","df.tail(5)"],"execution_count":null,"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>bdd</th>\n","      <th>sbt</th>\n","      <th>bdd_input</th>\n","      <th>bdd_label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>4995</th>\n","      <td>Fonction_4996/bdd_Fonction_4996_1/v/2/m/-1/Fon...</td>\n","      <td>Fonction_4996/Fonction_4996/v/v/m/m/v/v/1/1/f/...</td>\n","      <td>Fonction_4996/bdd_Fonction_4996_1/v/2/m/-1/Fon...</td>\n","      <td>Fonction_4996/bdd_Fonction_4996_1/v/2/m/-1/Fon...</td>\n","    </tr>\n","    <tr>\n","      <th>4996</th>\n","      <td>Fonction_4997/bdd_Fonction_4997_1/p/1/h/-8/Fon...</td>\n","      <td>Fonction_4997/Fonction_4997/p/p/h/h/v/v/4/4/h/...</td>\n","      <td>Fonction_4997/bdd_Fonction_4997_1/p/1/h/-8/Fon...</td>\n","      <td>Fonction_4997/bdd_Fonction_4997_1/p/1/h/-8/Fon...</td>\n","    </tr>\n","    <tr>\n","      <th>4997</th>\n","      <td>Fonction_4998/bdd_Fonction_4998_1/n/-5/c/-7/Fo...</td>\n","      <td>Fonction_4998/Fonction_4998/n/n/c/c/x/x/1/1/v/...</td>\n","      <td>Fonction_4998/bdd_Fonction_4998_1/n/-5/c/-7/Fo...</td>\n","      <td>Fonction_4998/bdd_Fonction_4998_1/n/-5/c/-7/Fo...</td>\n","    </tr>\n","    <tr>\n","      <th>4998</th>\n","      <td>Fonction_4999/bdd_Fonction_4999_1/a/7/a/-11/Fo...</td>\n","      <td>Fonction_4999/Fonction_4999/a/a/a/a/l/l/8/8/y/...</td>\n","      <td>Fonction_4999/bdd_Fonction_4999_1/a/7/a/-11/Fo...</td>\n","      <td>Fonction_4999/bdd_Fonction_4999_1/a/7/a/-11/Fo...</td>\n","    </tr>\n","    <tr>\n","      <th>4999</th>\n","      <td>Fonction_5000/bdd_Fonction_5000_1/l/5/k/-23/Fo...</td>\n","      <td>Fonction_5000/Fonction_5000/l/l/k/k/s/s/8/8/b/...</td>\n","      <td>Fonction_5000/bdd_Fonction_5000_1/l/5/k/-23/Fo...</td>\n","      <td>Fonction_5000/bdd_Fonction_5000_1/l/5/k/-23/Fo...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                                    bdd  \\\n","4995  Fonction_4996/bdd_Fonction_4996_1/v/2/m/-1/Fon...   \n","4996  Fonction_4997/bdd_Fonction_4997_1/p/1/h/-8/Fon...   \n","4997  Fonction_4998/bdd_Fonction_4998_1/n/-5/c/-7/Fo...   \n","4998  Fonction_4999/bdd_Fonction_4999_1/a/7/a/-11/Fo...   \n","4999  Fonction_5000/bdd_Fonction_5000_1/l/5/k/-23/Fo...   \n","\n","                                                    sbt  \\\n","4995  Fonction_4996/Fonction_4996/v/v/m/m/v/v/1/1/f/...   \n","4996  Fonction_4997/Fonction_4997/p/p/h/h/v/v/4/4/h/...   \n","4997  Fonction_4998/Fonction_4998/n/n/c/c/x/x/1/1/v/...   \n","4998  Fonction_4999/Fonction_4999/a/a/a/a/l/l/8/8/y/...   \n","4999  Fonction_5000/Fonction_5000/l/l/k/k/s/s/8/8/b/...   \n","\n","                                              bdd_input  \\\n","4995  Fonction_4996/bdd_Fonction_4996_1/v/2/m/-1/Fon...   \n","4996  Fonction_4997/bdd_Fonction_4997_1/p/1/h/-8/Fon...   \n","4997  Fonction_4998/bdd_Fonction_4998_1/n/-5/c/-7/Fo...   \n","4998  Fonction_4999/bdd_Fonction_4999_1/a/7/a/-11/Fo...   \n","4999  Fonction_5000/bdd_Fonction_5000_1/l/5/k/-23/Fo...   \n","\n","                                              bdd_label  \n","4995  Fonction_4996/bdd_Fonction_4996_1/v/2/m/-1/Fon...  \n","4996  Fonction_4997/bdd_Fonction_4997_1/p/1/h/-8/Fon...  \n","4997  Fonction_4998/bdd_Fonction_4998_1/n/-5/c/-7/Fo...  \n","4998  Fonction_4999/bdd_Fonction_4999_1/a/7/a/-11/Fo...  \n","4999  Fonction_5000/bdd_Fonction_5000_1/l/5/k/-23/Fo...  "]},"execution_count":26,"metadata":{},"output_type":"execute_result"}]},{"cell_type":"markdown","metadata":{"id":"CbrJIKI9Z5fz"},"source":["Il faut maintenant convertir nos données en numpy array"]},{"cell_type":"code","metadata":{"id":"lGzjNfS5Z5fz","outputId":"d58b7373-8d96-4777-a59e-fb56cd46b50a"},"source":["\n","encoder_input = np.array(df.sbt)\n","decoder_input = np.array(df.bdd_input)\n","decoder_label = np.array(df.bdd_label)\n","\n","df.head(10)"],"execution_count":null,"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>bdd</th>\n","      <th>sbt</th>\n","      <th>bdd_input</th>\n","      <th>bdd_label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Fonction_1/bdd_Fonction_1_1/l/-9/b/13/Fonction...</td>\n","      <td>Fonction_1/Fonction_1/l/l/b/b/i/i/4/4/x/x/1/1/...</td>\n","      <td>Fonction_1/bdd_Fonction_1_1/l/-9/b/13/Fonction...</td>\n","      <td>Fonction_1/bdd_Fonction_1_1/l/-9/b/13/Fonction...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Fonction_2/bdd_Fonction_2_1/c/0/f/10/Fonction_...</td>\n","      <td>Fonction_2/Fonction_2/c/c/f/f/c/c/6/6/d/d/5/5/...</td>\n","      <td>Fonction_2/bdd_Fonction_2_1/c/0/f/10/Fonction_...</td>\n","      <td>Fonction_2/bdd_Fonction_2_1/c/0/f/10/Fonction_...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Fonction_3/bdd_Fonction_3_1/j/3/w/-19/Fonction...</td>\n","      <td>Fonction_3/Fonction_3/j/j/w/w/p/p/9/9/l/l/6/6/...</td>\n","      <td>Fonction_3/bdd_Fonction_3_1/j/3/w/-19/Fonction...</td>\n","      <td>Fonction_3/bdd_Fonction_3_1/j/3/w/-19/Fonction...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Fonction_4/bdd_Fonction_4_1/t/1/k/13/Fonction_...</td>\n","      <td>Fonction_4/Fonction_4/t/t/k/k/g/g/8/8/u/u/7/7/...</td>\n","      <td>Fonction_4/bdd_Fonction_4_1/t/1/k/13/Fonction_...</td>\n","      <td>Fonction_4/bdd_Fonction_4_1/t/1/k/13/Fonction_...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Fonction_5/bdd_Fonction_5_1/y/5/d/-5/Fonction_...</td>\n","      <td>Fonction_5/Fonction_5/y/y/d/d/l/l/4/4/g/g/3/3/...</td>\n","      <td>Fonction_5/bdd_Fonction_5_1/y/5/d/-5/Fonction_...</td>\n","      <td>Fonction_5/bdd_Fonction_5_1/y/5/d/-5/Fonction_...</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>Fonction_6/bdd_Fonction_6_1/a/-1/j/-3/Fonction...</td>\n","      <td>Fonction_6/Fonction_6/a/a/j/j/e/e/10/10/w/w/7/...</td>\n","      <td>Fonction_6/bdd_Fonction_6_1/a/-1/j/-3/Fonction...</td>\n","      <td>Fonction_6/bdd_Fonction_6_1/a/-1/j/-3/Fonction...</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>Fonction_7/bdd_Fonction_7_1/h/1/x/0/Fonction_7...</td>\n","      <td>Fonction_7/Fonction_7/h/h/x/x/q/q/6/6/g/g/8/8/...</td>\n","      <td>Fonction_7/bdd_Fonction_7_1/h/1/x/0/Fonction_7...</td>\n","      <td>Fonction_7/bdd_Fonction_7_1/h/1/x/0/Fonction_7...</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>Fonction_8/bdd_Fonction_8_1/k/-4/a/0/Fonction_...</td>\n","      <td>Fonction_8/Fonction_8/k/k/a/a/y/y/0/0/e/e/3/3/...</td>\n","      <td>Fonction_8/bdd_Fonction_8_1/k/-4/a/0/Fonction_...</td>\n","      <td>Fonction_8/bdd_Fonction_8_1/k/-4/a/0/Fonction_...</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>Fonction_9/bdd_Fonction_9_1/o/0/f/6/Fonction_9...</td>\n","      <td>Fonction_9/Fonction_9/o/o/f/f/g/g/8/8/c/c/1/1/...</td>\n","      <td>Fonction_9/bdd_Fonction_9_1/o/0/f/6/Fonction_9...</td>\n","      <td>Fonction_9/bdd_Fonction_9_1/o/0/f/6/Fonction_9...</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>Fonction_10/bdd_Fonction_10_1/p/9/r/-1/Fonctio...</td>\n","      <td>Fonction_10/Fonction_10/p/p/r/r/j/j/7/7/i/i/2/...</td>\n","      <td>Fonction_10/bdd_Fonction_10_1/p/9/r/-1/Fonctio...</td>\n","      <td>Fonction_10/bdd_Fonction_10_1/p/9/r/-1/Fonctio...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                                 bdd  \\\n","0  Fonction_1/bdd_Fonction_1_1/l/-9/b/13/Fonction...   \n","1  Fonction_2/bdd_Fonction_2_1/c/0/f/10/Fonction_...   \n","2  Fonction_3/bdd_Fonction_3_1/j/3/w/-19/Fonction...   \n","3  Fonction_4/bdd_Fonction_4_1/t/1/k/13/Fonction_...   \n","4  Fonction_5/bdd_Fonction_5_1/y/5/d/-5/Fonction_...   \n","5  Fonction_6/bdd_Fonction_6_1/a/-1/j/-3/Fonction...   \n","6  Fonction_7/bdd_Fonction_7_1/h/1/x/0/Fonction_7...   \n","7  Fonction_8/bdd_Fonction_8_1/k/-4/a/0/Fonction_...   \n","8  Fonction_9/bdd_Fonction_9_1/o/0/f/6/Fonction_9...   \n","9  Fonction_10/bdd_Fonction_10_1/p/9/r/-1/Fonctio...   \n","\n","                                                 sbt  \\\n","0  Fonction_1/Fonction_1/l/l/b/b/i/i/4/4/x/x/1/1/...   \n","1  Fonction_2/Fonction_2/c/c/f/f/c/c/6/6/d/d/5/5/...   \n","2  Fonction_3/Fonction_3/j/j/w/w/p/p/9/9/l/l/6/6/...   \n","3  Fonction_4/Fonction_4/t/t/k/k/g/g/8/8/u/u/7/7/...   \n","4  Fonction_5/Fonction_5/y/y/d/d/l/l/4/4/g/g/3/3/...   \n","5  Fonction_6/Fonction_6/a/a/j/j/e/e/10/10/w/w/7/...   \n","6  Fonction_7/Fonction_7/h/h/x/x/q/q/6/6/g/g/8/8/...   \n","7  Fonction_8/Fonction_8/k/k/a/a/y/y/0/0/e/e/3/3/...   \n","8  Fonction_9/Fonction_9/o/o/f/f/g/g/8/8/c/c/1/1/...   \n","9  Fonction_10/Fonction_10/p/p/r/r/j/j/7/7/i/i/2/...   \n","\n","                                           bdd_input  \\\n","0  Fonction_1/bdd_Fonction_1_1/l/-9/b/13/Fonction...   \n","1  Fonction_2/bdd_Fonction_2_1/c/0/f/10/Fonction_...   \n","2  Fonction_3/bdd_Fonction_3_1/j/3/w/-19/Fonction...   \n","3  Fonction_4/bdd_Fonction_4_1/t/1/k/13/Fonction_...   \n","4  Fonction_5/bdd_Fonction_5_1/y/5/d/-5/Fonction_...   \n","5  Fonction_6/bdd_Fonction_6_1/a/-1/j/-3/Fonction...   \n","6  Fonction_7/bdd_Fonction_7_1/h/1/x/0/Fonction_7...   \n","7  Fonction_8/bdd_Fonction_8_1/k/-4/a/0/Fonction_...   \n","8  Fonction_9/bdd_Fonction_9_1/o/0/f/6/Fonction_9...   \n","9  Fonction_10/bdd_Fonction_10_1/p/9/r/-1/Fonctio...   \n","\n","                                           bdd_label  \n","0  Fonction_1/bdd_Fonction_1_1/l/-9/b/13/Fonction...  \n","1  Fonction_2/bdd_Fonction_2_1/c/0/f/10/Fonction_...  \n","2  Fonction_3/bdd_Fonction_3_1/j/3/w/-19/Fonction...  \n","3  Fonction_4/bdd_Fonction_4_1/t/1/k/13/Fonction_...  \n","4  Fonction_5/bdd_Fonction_5_1/y/5/d/-5/Fonction_...  \n","5  Fonction_6/bdd_Fonction_6_1/a/-1/j/-3/Fonction...  \n","6  Fonction_7/bdd_Fonction_7_1/h/1/x/0/Fonction_7...  \n","7  Fonction_8/bdd_Fonction_8_1/k/-4/a/0/Fonction_...  \n","8  Fonction_9/bdd_Fonction_9_1/o/0/f/6/Fonction_9...  \n","9  Fonction_10/bdd_Fonction_10_1/p/9/r/-1/Fonctio...  "]},"execution_count":27,"metadata":{},"output_type":"execute_result"}]},{"cell_type":"markdown","metadata":{"id":"rrSXdnoQZ5fz"},"source":["On repartit nos données en set de test et set d'entrainnement, on choisit de consacrer 90% des données pour l'entrainement et 10% pour le test :"]},{"cell_type":"code","metadata":{"id":"GlfEhmV7Z5fz","outputId":"2cc815e8-a6f3-48e8-b33d-01ff1b3117bc"},"source":["total = num_folder\n","test_size = 0.1\n","\n","train_encoder_input = encoder_input[:-int(total*test_size)]\n","train_decoder_input = decoder_input[:-int(total*test_size)]\n","train_decoder_label = decoder_label[:-int(total*test_size)]\n","\n","test_encoder_input = encoder_input[-int(total*test_size):]\n","test_decoder_input = decoder_input[-int(total*test_size):]\n","test_decoder_label = decoder_label[-int(total*test_size):]\n","'''\n","print(\"train dataset shape\")\n","print(train_encoder_input.shape)\n","print(train_decoder_input.shape)\n","print(train_decoder_label.shape)\n","\n","print(\"\\n\\ntest dataset shape\")\n","print(test_encoder_input.shape)\n","print(test_decoder_input.shape)\n","print(test_decoder_label.shape)\n","'''"],"execution_count":null,"outputs":[{"data":{"text/plain":["'\\nprint(\"train dataset shape\")\\nprint(train_encoder_input.shape)\\nprint(train_decoder_input.shape)\\nprint(train_decoder_label.shape)\\n\\nprint(\"\\n\\ntest dataset shape\")\\nprint(test_encoder_input.shape)\\nprint(test_decoder_input.shape)\\nprint(test_decoder_label.shape)\\n'"]},"execution_count":28,"metadata":{},"output_type":"execute_result"}]},{"cell_type":"markdown","metadata":{"id":"PLhvt0cVZ5f0"},"source":["# Encodage des données "]},{"cell_type":"markdown","metadata":{"id":"-N6UNOIIZ5f0"},"source":["Il faut maintenant encoder nos données, c'est a dire convertir nos suites de variables en une sequence de nombres, cette fonction prend en entrée nos variables et des parametres pour l'encodage et renvoit une version encodée. "]},{"cell_type":"code","metadata":{"id":"eMO9MZ5ZZ5f0"},"source":["def encode(variables,char_to_ind, dim1, dim2,type):# type 0 encoder, 1 decoder_input, 2 decoder_label\n","    encoded_variables_matrix = np.full((dim1,dim2),char_to_ind['/'])\n","    #print('Encoding Matrix shape : ',encoded_variables_matrix.shape)\n","    for i,vars in enumerate(variables):\n","        j=0\n","        #print(vars)\n","        if type == 1:\n","            encoded_variables_matrix[i,j]=char_to_ind['sostoken ']\n","            j=j+1\n","        \n","        for var in (vars):\n","            #print(var)\n","            #print(' j :',j)\n","            encoded_variables_matrix[i,j]=char_to_ind[var]\n","\n","            j=j+1\n","        if type == 2:\n","            encoded_variables_matrix[i,j]=char_to_ind[' eostoken']\n","            j=j+1\n","\n","    return encoded_variables_matrix"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"LU7klViFZ5f0"},"source":["La fonction suivante permet d'encoder une seule sequence de variables"]},{"cell_type":"code","metadata":{"id":"blDCHYHAZ5f0"},"source":["def encode_unique_var(text):\n","    encoded_matrix_unique = np.full(73,char_to_ind_sbt['/'])\n","    for i,char in enumerate(text):\n","        encoded_matrix_unique[i]=char_to_ind_sbt[char]\n","\n","    return encoded_matrix_unique"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"IcgkffuSZ5f1"},"source":["Nous générons nos données encodées avec les fonction précédentes"]},{"cell_type":"code","metadata":{"id":"vV0i0iu6Z5f1"},"source":["#print(\"train dataset shape\")\n","train_encoder_input_encoded = encode(train_encoder_input, char_to_ind_sbt,len(train_encoder_input),len_total_chain_sbt,0)\n","train_decoder_input_encoded = encode(train_decoder_input, char_to_ind_bdd,len(train_decoder_input),len_total_chain_bdd,1)\n","train_decoder_label_encoded = encode(train_decoder_label, char_to_ind_bdd,len(train_decoder_label),len_total_chain_bdd,2)\n","#print(\"\\n\\ntest dataset shape\")\n","\n","test_encoder_input_encoded = encode(test_encoder_input, char_to_ind_sbt,len(test_encoder_input),len_total_chain_sbt,0)\n","test_decoder_input_encoded = encode(test_decoder_input, char_to_ind_bdd,len(test_decoder_input),len_total_chain_bdd,1)\n","test_decoder_label_encoded = encode(test_decoder_label, char_to_ind_bdd,len(test_decoder_label),len_total_chain_bdd,2)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"sFQzL9CyZ5f1"},"source":["la fonction suivante permet de passer d'une sequence encodée a une sequence lisible de variable"]},{"cell_type":"code","metadata":{"id":"YBPSGim7Z5f1"},"source":["def decode ( encoded_sequence, ind_to_char):\n","    decoded_sequence = []\n","    for var in encoded_sequence:\n","        decoded_sequence.append(ind_to_char[var])\n","    return ''.join(decoded_sequence)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2PweeltVZ5f1"},"source":["decode(train_decoder_label_encoded[0],ind_to_char_bdd)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0g7zef0HZ5f1"},"source":["# Création du modèle "]},{"cell_type":"code","metadata":{"id":"PTtikrfCZ5f2"},"source":["from keras.layers import Input,Embedding,LSTM,Dense,Concatenate,Attention\n","from keras.models import Model\n","from keras import backend as K\n","\n","#hyperparameters\n","embedding_size = 256\n","hidden_size = 1024\n","\n","# trainer model (generator model will use the same encoder tho)\n","encoder_input = Input(shape=[len_total_chain_sbt]) # size chain SBT \n","encoder_embedding = Embedding(len_total_chain_sbt,embedding_size,mask_zero=True)\n","encoder_embedded = encoder_embedding(encoder_input)\n","\n","encoder_lstm1 = LSTM(hidden_size,return_sequences=True,return_state=True,dropout=0.2,recurrent_dropout=0)\n","encoder_output1,encoder_h1,encoder_c1 = encoder_lstm1(encoder_embedded)\n","\n","encoder_lstm2 = LSTM(hidden_size,return_sequences=True,return_state=True,dropout=0.2,recurrent_dropout=0)\n","encoder_output2,encoder_h2,encoder_c2 = encoder_lstm2(encoder_output1)\n","\n","encoder_lstm3 = LSTM(hidden_size,return_sequences=True,return_state=True,dropout=0.2,recurrent_dropout=0)\n","encoder_output3,encoder_h3,encoder_c3 = encoder_lstm3(encoder_output1)\n","\n","decoder_input = Input(shape=(None,))\n","decoder_embedding = Embedding(len_total_chain_bdd,embedding_size,mask_zero=True) # len chain bdd\n","decoder_embedded = decoder_embedding(decoder_input)\n","\n","decoder_lstm = LSTM(hidden_size,return_sequences=True,return_state=True,dropout=0.2,recurrent_dropout=0)\n","decoder_output,_,_ = decoder_lstm(decoder_embedded,initial_state=[encoder_h3,encoder_c3])\n","\n","attn_layer = Attention()\n","attn_context = attn_layer([decoder_output,encoder_output3])\n","\n","decoder_output = Concatenate(axis=-1)([decoder_output,attn_context])\n","tanh_dense= Dense(hidden_size*2,activation=K.tanh)\n","decoder_output = tanh_dense(decoder_output)\n","\n","softmax_dense = Dense(number_char_variables_bdd,activation='softmax')\n","decoder_output = softmax_dense(decoder_output)\n","\n","trainer_model = Model([encoder_input,decoder_input],decoder_output)\n","trainer_model.compile(loss='sparse_categorical_crossentropy',optimizer='adam',metrics=['accuracy'])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_7gtKnmjZ5f2"},"source":["Entrainement du modèle sur 25 epochs :"]},{"cell_type":"code","metadata":{"id":"A6xevg6XZ5f2"},"source":["print(\"\\nTraining of the model ... \\n\")\n","trainer_hist =trainer_model.fit([train_encoder_input_encoded,train_decoder_input_encoded],train_decoder_label_encoded,epochs=25,batch_size=128,validation_split=0.2, verbose=1)\n","print(\"\\nTraining completed ! \\n\")\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UGiWdQ-aZ5f2"},"source":["Sauvegarde des poids du modèle, ce qui permet de pouvoir le charger ( c'est à dire d'etre en mesure de faire des prédictions sans avoir à ré-entrainer le modele ) :"]},{"cell_type":"code","metadata":{"id":"75J1LpMzZ5f3"},"source":["print(\"\\nSaving the model ... \\n\")\n","trainer_model.save_weights('Variables_attention_weights.h5')\n","print(\"\\nModel saved !\\n\")\n","print(\"\\nPLoting the metrics / epochs ... \\n\")\n","losses = pd.DataFrame(trainer_model.history.history)\n","losses.plot()\n","#trainer_model.load_weights('Variables_attention_weights.h5')\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"WbkchTWVZ5f2"},"source":["Evalutaion de la précision du modèle : "]},{"cell_type":"code","metadata":{"id":"xe4WMapgZ5f2"},"source":["print(\"\\nEvaluating the model ... \\n\")\n","score = trainer_model.evaluate([train_encoder_input_encoded,train_decoder_input_encoded], train_decoder_label_encoded, verbose=0)\n","print(\"%s: %.2f%%\" % (trainer_model.metrics_names[1], score[1]*100))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7v8ztk4oZ5f3"},"source":["#generator model\n","gen_encoder = Model([encoder_input],[encoder_output3,encoder_h3,encoder_c3])\n","\n","gen_decoder_values_input = Input(shape=(len_total_chain_sbt,hidden_size))\n","gen_decoder_h_input = Input(shape=[hidden_size])\n","gen_decoder_c_input = Input(shape=[hidden_size])\n","\n","gen_decoder_embedded = decoder_embedding(decoder_input)\n","gen_decoder_output,gen_decoder_h,gen_decoder_c = decoder_lstm(gen_decoder_embedded,initial_state=[gen_decoder_h_input,gen_decoder_c_input])\n","\n","attn_context = attn_layer([gen_decoder_output,gen_decoder_values_input])\n","gen_decoder_output = Concatenate(axis=-1)([gen_decoder_output,attn_context])\n","\n","gen_decoder_output = tanh_dense(gen_decoder_output)\n","gen_decoder_output = softmax_dense(gen_decoder_output)\n","\n","gen_decoder = Model([decoder_input]+[gen_decoder_values_input,gen_decoder_h_input,gen_decoder_c_input],[gen_decoder_output,gen_decoder_h,gen_decoder_c])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"s0plOleopAFc"},"source":["# Test"]},{"cell_type":"code","metadata":{"id":"iyCRP-viZ5f3"},"source":["def generate_from_encoder_input(encoder_input):\n","    encoder_input = encoder_input.reshape(1,-1)\n","    values,h,c = gen_encoder.predict(encoder_input)\n","    \n","    single_tok = np.zeros((1,1))\n","    single_tok[0,0] = char_to_ind_bdd['sostoken ']\n","    decoder_input = single_tok\n","    \n","    generated = []\n","    count = 0\n","    while(True):\n","        decoder_output,new_h,new_c = gen_decoder.predict([decoder_input]+[values,h,c])\n","        count +=1\n","        \n","        sampled_index = np.argmax(decoder_output[0,-1,:])\n","        sampled_word = ind_to_char_bdd[sampled_index]\n","        \n","        if sampled_word != ' eostoken' and sampled_index != 0:\n","            generated.append(sampled_word)\n","        if count >= len_total_chain_bdd or sampled_word == ' eostoken':\n","            break\n","        \n","        h,c = new_h,new_c\n","        decoder_input[0,0] = sampled_index\n","    \n","    generated = ''.join(generated)\n","    return generated"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wDUG96RyZ5f3"},"source":["# test de prediciton sur des données \n","'''\n","for i in range(10,20):\n","    print(\"\\n<<sample encoder input SBT >>\")\n","    print(decode(train_encoder_input_encoded[i],ind_to_char_sbt))\n","    print(\"\\n\")\n","    print(\"<<generated BDD >>\")\n","    print(generate_from_encoder_input(train_encoder_input_encoded[i]))\n","    print(\"\\n\")\n","    print(\"<<Expected BDD>>\")\n","    print(decode(train_decoder_label_encoded[i],ind_to_char_bdd))\n","    print(\"========================================\\n\")\n","'''"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4RzbwEy8Z5f4"},"source":["def return_generated_var(input_encoded):\n","    generated = generate_from_encoder_input(input_encoded)\n","    generated = generated.split('/')\n","    return generated"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0oWNafrVZ5f4"},"source":["#print(generate_from_encoder_input(train_encoder_input_encoded[0]))\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"K2uiD_xsZ5f4"},"source":["#return_generated_var(train_encoder_input_encoded[0])"],"execution_count":null,"outputs":[]}]}